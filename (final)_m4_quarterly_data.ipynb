{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:01.880078Z",
     "start_time": "2025-03-14T01:31:01.804510Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "from collections import defaultdict\n",
    "import ast"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:03.993672Z",
     "start_time": "2025-03-14T01:31:03.991116Z"
    }
   },
   "source": [
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:05.738057Z",
     "start_time": "2025-03-14T01:31:05.733877Z"
    }
   },
   "source": [
    "def safe_literal_eval(val):\n",
    "    \"\"\"\n",
    "    주어진 값이 문자열로 되어 있고 '['로 시작하면 ast.literal_eval을 시도하고,\n",
    "    그렇지 않으면 그대로 반환하는 함수.\n",
    "    \"\"\"\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except Exception as e:\n",
    "            print(\"literal_eval 오류:\", e, \"값:\", val)\n",
    "            return None\n",
    "    # 문자열이 아니면 그대로 반환 (예: 이미 리스트 또는 numpy 배열인 경우)\n",
    "    return val"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:09.899267Z",
     "start_time": "2025-03-14T01:31:07.174631Z"
    }
   },
   "source": [
    "# 1. 병합된 데이터 로드 (CSV 파일)\n",
    "tsf_file_path = \"./dataset/final_dataset/M4_Quarterly_Merged.csv\"  # CSV 파일 경로\n",
    "df_q = pd.read_csv(tsf_file_path)\n",
    "\n",
    "# 2. 병합된 데이터에서 'category' 컬럼을 기준으로 도메인별 그룹화\n",
    "domain_time_series = defaultdict(dict)\n",
    "for idx, row in df_q.iterrows():\n",
    "    category = row['category']  # 도메인 정보 (예: Macro, Finance 등)\n",
    "    ts_id = row['series_name']\n",
    "    # series_value 컬럼은 문자열 형태의 리스트이므로 안전하게 변환\n",
    "    values = safe_literal_eval(row['series_value'])\n",
    "    if values is None:\n",
    "        continue\n",
    "    domain_time_series[category][ts_id] = (row['start_timestamp'], values)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:12.882846Z",
     "start_time": "2025-03-14T01:31:10.423417Z"
    }
   },
   "source": [
    "domain_time_series"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:13.487687Z",
     "start_time": "2025-03-14T01:31:12.884400Z"
    }
   },
   "source": [
    "def check_missing_values(domain_time_series):\n",
    "    \"\"\"\n",
    "    시계열 데이터에서 결측값(NaN)을 확인합니다.\n",
    "    \"\"\"\n",
    "    missing_stats = {\n",
    "        'total_series': 0,\n",
    "        'series_with_missing': 0,\n",
    "        'total_values': 0,\n",
    "        'total_missing': 0,\n",
    "        'series_details': []\n",
    "    }\n",
    "    \n",
    "    # 먼저 모든 시계열의 총 수를 계산\n",
    "    total_series = 0\n",
    "    for domain, series_dict in domain_time_series.items():\n",
    "        total_series += len(series_dict)\n",
    "    \n",
    "    missing_stats['total_series'] = total_series\n",
    "    \n",
    "    # 각 도메인과 시리즈를 반복\n",
    "    for domain, series_dict in domain_time_series.items():\n",
    "        for ts_id, (start_time, values) in series_dict.items():\n",
    "            total = len(values)\n",
    "            missing = sum(np.isnan(v) for v in values)\n",
    "            missing_ratio = missing / total if total > 0 else 0\n",
    "            \n",
    "            missing_stats['total_values'] += total\n",
    "            missing_stats['total_missing'] += missing\n",
    "            \n",
    "            if missing > 0:\n",
    "                missing_stats['series_with_missing'] += 1\n",
    "                missing_stats['series_details'].append({\n",
    "                    'domain': domain,\n",
    "                    'ts_id': ts_id,\n",
    "                    'total_values': total,\n",
    "                    'missing_values': missing,\n",
    "                    'missing_ratio': missing_ratio\n",
    "                })\n",
    "    \n",
    "    # 전체 결측치 비율 계산\n",
    "    if missing_stats['total_values'] > 0:\n",
    "        missing_stats['overall_missing_ratio'] = missing_stats['total_missing'] / missing_stats['total_values']\n",
    "    else:\n",
    "        missing_stats['overall_missing_ratio'] = 0\n",
    "        \n",
    "    return missing_stats\n",
    "\n",
    "# 결측값 확인\n",
    "missing_stats = check_missing_values(domain_time_series)\n",
    "print(\"\\n===== 결측값 통계 =====\")\n",
    "print(f\"전체 시계열 수: {missing_stats['total_series']}\")\n",
    "print(f\"결측값이 있는 시계열 수: {missing_stats['series_with_missing']}\")\n",
    "print(f\"전체 데이터 포인트 수: {missing_stats['total_values']}\")\n",
    "print(f\"전체 결측값 수: {missing_stats['total_missing']}\")\n",
    "print(f\"전체 결측치 비율: {missing_stats['overall_missing_ratio']:.6f} ({missing_stats['overall_missing_ratio']*100:.4f}%)\")\n",
    "\n",
    "# 결측값이 있는 경우 세부 정보 표시\n",
    "if missing_stats['series_with_missing'] > 0:\n",
    "    print(\"\\n결측값이 있는 시계열 세부 정보:\")\n",
    "    for detail in missing_stats['series_details']:\n",
    "        print(f\" {detail['domain']}-{detail['ts_id']}: {detail['missing_values']} 결측값 / {detail['total_values']} 전체 ({detail['missing_ratio']*100:.2f}%)\")"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:14.643055Z",
     "start_time": "2025-03-14T01:31:13.492895Z"
    }
   },
   "source": [
    "def check_time_series_lengths(domain_time_series):\n",
    "    \"\"\"\n",
    "    시계열 데이터의 길이 분포를 확인하고 요약합니다.\n",
    "    \"\"\"\n",
    "    # 각 시계열의 길이 저장\n",
    "    lengths = {}\n",
    "    total_series = 0\n",
    "    \n",
    "    # 도메인과 시계열 순회\n",
    "    for domain, series_dict in domain_time_series.items():\n",
    "        for ts_id, (start_time, values) in series_dict.items():\n",
    "            key = f\"{domain}-{ts_id}\"  # 도메인과 시계열 ID를 합쳐서 고유 키 생성\n",
    "            lengths[key] = len(values)\n",
    "            total_series += 1\n",
    "    \n",
    "    # 길이 분포 요약\n",
    "    length_counts = {}\n",
    "    for length in set(lengths.values()):\n",
    "        length_counts[length] = list(lengths.values()).count(length)\n",
    "    \n",
    "    # 정렬된 길이 분포\n",
    "    sorted_length_counts = dict(sorted(length_counts.items()))\n",
    "    \n",
    "    # 요약 통계\n",
    "    min_length = min(lengths.values()) if lengths else 0\n",
    "    max_length = max(lengths.values()) if lengths else 0\n",
    "    avg_length = sum(lengths.values()) / len(lengths) if lengths else 0\n",
    "    \n",
    "    print(f\"시계열 총 개수: {len(lengths)}\")\n",
    "    print(f\"최소 길이: {min_length}\")\n",
    "    print(f\"최대 길이: {max_length}\")\n",
    "    print(f\"평균 길이: {avg_length:.2f}\")\n",
    "    \n",
    "    print(\"\\n길이 분포:\")\n",
    "    for length, count in sorted_length_counts.items():\n",
    "        print(f\" 길이 {length}: {count}개 시계열 ({count/len(lengths)*100:.2f}%)\")\n",
    "    \n",
    "    # 가장 짧은 시계열과 가장 긴 시계열 찾기\n",
    "    if lengths:\n",
    "        shortest_ts = min(lengths, key=lengths.get)\n",
    "        longest_ts = max(lengths, key=lengths.get)\n",
    "        print(f\"\\n가장 짧은 시계열: {shortest_ts} (길이: {lengths[shortest_ts]})\")\n",
    "        print(f\"가장 긴 시계열: {longest_ts} (길이: {lengths[longest_ts]})\")\n",
    "    \n",
    "    # 시작 시간 분포 확인\n",
    "    start_times = {}\n",
    "    for domain, series_dict in domain_time_series.items():\n",
    "        for ts_id, (start_time, _) in series_dict.items():\n",
    "            if isinstance(start_time, str):\n",
    "                start_time_str = start_time\n",
    "            else:\n",
    "                # datetime 객체라면 문자열로 변환\n",
    "                try:\n",
    "                    start_time_str = start_time.strftime('%Y-%m-%d')\n",
    "                except:\n",
    "                    start_time_str = str(start_time)\n",
    "                    \n",
    "            if start_time_str not in start_times:\n",
    "                start_times[start_time_str] = 0\n",
    "            start_times[start_time_str] += 1\n",
    "    \n",
    "    print(\"\\n시작 시간 분포:\")\n",
    "    for start_time, count in sorted(start_times.items()):\n",
    "        print(f\" {start_time}: {count}개 시계열\")\n",
    "    \n",
    "    return lengths\n",
    "\n",
    "# 함수 실행\n",
    "lengths = check_time_series_lengths(domain_time_series)\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 시계열 길이 분포 히스토그램\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(list(lengths.values()), bins=20)\n",
    "plt.title('시계열 길이 분포')\n",
    "plt.xlabel('길이')\n",
    "plt.ylabel('시계열 개수')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 수정된 산점도 - 도메인별로 색상 구분\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# 도메인 목록 추출 (키에서 하이픈 이전 부분)\n",
    "domains = list(set([key.split('-')[0] for key in lengths.keys()]))\n",
    "domain_colors = plt.cm.tab10(np.linspace(0, 1, len(domains)))\n",
    "\n",
    "# 도메인별로 다른 색상 사용\n",
    "for i, domain in enumerate(domains):\n",
    "    domain_keys = [k for k in lengths.keys() if k.startswith(domain+'-')]\n",
    "    domain_values = [lengths[k] for k in domain_keys]\n",
    "    \n",
    "    # 시리즈 ID 부분만 추출 (하이픈 이후 부분)\n",
    "    series_ids = [k.split('-')[1] for k in domain_keys]\n",
    "    \n",
    "    plt.scatter(range(len(domain_keys)), domain_values, \n",
    "                color=domain_colors[i], alpha=0.7, label=domain)\n",
    "\n",
    "plt.title('도메인 및 시계열 ID별 길이')\n",
    "plt.xlabel('시계열 인덱스')\n",
    "plt.ylabel('길이')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 도메인별 길이 박스플롯\n",
    "plt.figure(figsize=(14, 7))\n",
    "domain_data = []\n",
    "domain_names = []\n",
    "\n",
    "for domain in domains:\n",
    "    domain_keys = [k for k in lengths.keys() if k.startswith(domain+'-')]\n",
    "    domain_data.append([lengths[k] for k in domain_keys])\n",
    "    domain_names.append(f\"{domain} (n={len(domain_keys)})\")\n",
    "\n",
    "plt.boxplot(domain_data, labels=domain_names)\n",
    "plt.title('도메인별 시계열 길이 분포')\n",
    "plt.ylabel('길이')\n",
    "plt.grid(True, axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:31:18.363059Z",
     "start_time": "2025-03-14T01:31:14.661629Z"
    }
   },
   "source": [
    "def calculate_basic_statistics(domain_time_series):\n",
    "    \"\"\"\n",
    "    각 시계열의 기본 통계량을 계산합니다.\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    \n",
    "    # 각 도메인과 시계열 반복\n",
    "    for domain, series_dict in domain_time_series.items():\n",
    "        for ts_id, (start_time, values) in series_dict.items():\n",
    "            # NaN 값 제외한 유효한 값들만 사용\n",
    "            values_clean = np.array([v for v in values if not np.isnan(v)])\n",
    "            \n",
    "            if len(values_clean) > 0:\n",
    "                # 기본 통계량 계산\n",
    "                stat = {\n",
    "                    'domain': domain,\n",
    "                    'ts_id': ts_id,\n",
    "                    'length': len(values),\n",
    "                    'mean': np.mean(values_clean),\n",
    "                    'median': np.median(values_clean),\n",
    "                    'std': np.std(values_clean),\n",
    "                    'min': np.min(values_clean),\n",
    "                    'max': np.max(values_clean),\n",
    "                    'range': np.max(values_clean) - np.min(values_clean),\n",
    "                    'cv': np.std(values_clean) / np.mean(values_clean) if np.mean(values_clean) != 0 else np.nan\n",
    "                }\n",
    "                stats.append(stat)\n",
    "    \n",
    "    # DataFrame으로 변환\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    return stats_df\n",
    "\n",
    "# 기본 통계량 계산 및 확인\n",
    "statistics_df = calculate_basic_statistics(domain_time_series)\n",
    "\n",
    "# 전체 통계량 요약\n",
    "print(\"전체 시계열 통계량 요약:\")\n",
    "print(statistics_df.describe())\n",
    "\n",
    "# 도메인별 통계량 요약\n",
    "print(\"\\n도메인별 통계량 요약:\")\n",
    "for domain in statistics_df['domain'].unique():\n",
    "    domain_stats = statistics_df[statistics_df['domain'] == domain]\n",
    "    print(f\"\\n== {domain} 도메인 통계량 (총 {len(domain_stats)}개 시계열) ==\")\n",
    "    print(domain_stats.describe())\n",
    "    \n",
    "# 도메인별 통계량 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 도메인별 평균값 비교\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='domain', y='mean', data=statistics_df)\n",
    "plt.title('도메인별 시계열 평균값 분포')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 도메인별 표준편차 비교\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='domain', y='std', data=statistics_df)\n",
    "plt.title('도메인별 시계열 표준편차 분포')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 도메인별 변동계수(CV) 비교\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='domain', y='cv', data=statistics_df)\n",
    "plt.title('도메인별 시계열 변동계수(CV) 분포')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 평균 vs 표준편차 산점도 (도메인별 색상)\n",
    "plt.figure(figsize=(14, 8))\n",
    "domains = statistics_df['domain'].unique()\n",
    "for i, domain in enumerate(domains):\n",
    "    domain_data = statistics_df[statistics_df['domain'] == domain]\n",
    "    plt.scatter(domain_data['mean'], domain_data['std'], \n",
    "                alpha=0.7, label=domain)\n",
    "\n",
    "plt.title('시계열 평균 vs 표준편차 (도메인별)')\n",
    "plt.xlabel('평균')\n",
    "plt.ylabel('표준편차')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 도메인별 주요 통계량 요약 테이블\n",
    "domain_summary = statistics_df.groupby('domain').agg({\n",
    "    'length': ['count', 'mean'],\n",
    "    'mean': ['mean', 'min', 'max'],\n",
    "    'median': ['mean', 'min', 'max'],\n",
    "    'std': ['mean', 'min', 'max'],\n",
    "    'range': ['mean', 'min', 'max'],\n",
    "    'cv': ['mean', 'min', 'max']\n",
    "})\n",
    "\n",
    "print(\"\\n도메인별 통계량 요약 테이블:\")\n",
    "print(domain_summary)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "def apply_log_transformation(domain_time_series):\n",
    "    \"\"\"\n",
    "    시계열 데이터에 로그 변환을 적용하고 변환 전/후 통계를 비교합니다.\n",
    "    각 도메인별 샘플 시계열에 대한 변환 전/후를 시각화합니다.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy import stats\n",
    "    import random\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    \n",
    "    # 원본 데이터 통계량 계산\n",
    "    original_stats = []\n",
    "    \n",
    "    # 로그 변환 데이터 저장용 구조\n",
    "    log_transformed_series = {}\n",
    "    \n",
    "    # 각 도메인별 샘플 시계열 ID 저장 (랜덤 선택)\n",
    "    sample_series_ids = {}\n",
    "    \n",
    "    # 각 도메인과 시계열에 대한 처리\n",
    "    for domain, series_dict in domain_time_series.items():\n",
    "        if domain not in log_transformed_series:\n",
    "            log_transformed_series[domain] = {}\n",
    "            \n",
    "        # 이 도메인의 랜덤 시계열 ID 선택 (변환 전/후 비교용)\n",
    "        sample_series_ids[domain] = random.choice(list(series_dict.keys()))\n",
    "            \n",
    "        for ts_id, (start_time, values) in series_dict.items():\n",
    "            # 원본 데이터 통계 계산\n",
    "            values_clean = np.array([v for v in values if not np.isnan(v)])\n",
    "            \n",
    "            if len(values_clean) > 0:\n",
    "                stat = {\n",
    "                    'domain': domain,\n",
    "                    'ts_id': ts_id,\n",
    "                    'length': len(values),\n",
    "                    'mean': np.mean(values_clean),\n",
    "                    'median': np.median(values_clean),\n",
    "                    'std': np.std(values_clean),\n",
    "                    'min': np.min(values_clean),\n",
    "                    'max': np.max(values_clean),\n",
    "                    'range': np.max(values_clean) - np.min(values_clean),\n",
    "                    'cv': np.std(values_clean) / np.mean(values_clean) if np.mean(values_clean) != 0 else np.nan,\n",
    "                    'skewness': stats.skew(values_clean) if len(values_clean) > 2 else np.nan,\n",
    "                    'transformation': 'original'\n",
    "                }\n",
    "                original_stats.append(stat)\n",
    "                \n",
    "                # 로그 변환 적용 (NaN 값은 그대로 유지)\n",
    "                log_values = np.array([np.log(v) if not np.isnan(v) else np.nan for v in values])\n",
    "                log_transformed_series[domain][ts_id] = (start_time, log_values)\n",
    "    \n",
    "    # 로그 변환 데이터 통계량 계산\n",
    "    log_stats = []\n",
    "    \n",
    "    for domain, series_dict in log_transformed_series.items():\n",
    "        for ts_id, (start_time, values) in series_dict.items():\n",
    "            # 로그 변환 데이터 통계 계산\n",
    "            values_clean = np.array([v for v in values if not np.isnan(v)])\n",
    "            \n",
    "            if len(values_clean) > 0:\n",
    "                stat = {\n",
    "                    'domain': domain,\n",
    "                    'ts_id': ts_id,\n",
    "                    'length': len(values),\n",
    "                    'mean': np.mean(values_clean),\n",
    "                    'median': np.median(values_clean),\n",
    "                    'std': np.std(values_clean),\n",
    "                    'min': np.min(values_clean),\n",
    "                    'max': np.max(values_clean),\n",
    "                    'range': np.max(values_clean) - np.min(values_clean),\n",
    "                    'cv': np.std(values_clean) / np.mean(values_clean) if np.mean(values_clean) != 0 else np.nan,\n",
    "                    'skewness': stats.skew(values_clean) if len(values_clean) > 2 else np.nan,\n",
    "                    'transformation': 'log'\n",
    "                }\n",
    "                log_stats.append(stat)\n",
    "    \n",
    "    # 통계량 DataFrame 생성\n",
    "    original_df = pd.DataFrame(original_stats)\n",
    "    log_df = pd.DataFrame(log_stats)\n",
    "    \n",
    "    # 두 데이터프레임 합치기\n",
    "    combined_df = pd.concat([original_df, log_df])\n",
    "    \n",
    "    # 도메인별 로그 변환 전후 비교\n",
    "    domains = original_df['domain'].unique()\n",
    "    \n",
    "    # 각 도메인별로 로그 변환 전후 비교 시각화\n",
    "    for domain in domains:\n",
    "        domain_original = original_df[original_df['domain'] == domain]\n",
    "        domain_log = log_df[log_df['domain'] == domain]\n",
    "        \n",
    "        # 기본 통계량 출력\n",
    "        print(f\"\\n=== {domain} 도메인 로그 변환 전후 비교 ===\")\n",
    "        \n",
    "        print(\"\\n원본 데이터 통계:\")\n",
    "        print(domain_original[['mean', 'median', 'std', 'min', 'max', 'cv', 'skewness']].describe())\n",
    "        \n",
    "        print(\"\\n로그 변환 데이터 통계:\")\n",
    "        print(domain_log[['mean', 'median', 'std', 'min', 'max', 'cv', 'skewness']].describe())\n",
    "        \n",
    "        # 원본과 로그 변환 히스토그램 비교 (평균값 분포만 남김)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(domain_original['mean'], kde=True)\n",
    "        plt.title(f'{domain} 도메인 - 원본 데이터 평균 분포')\n",
    "        plt.xlabel('값')\n",
    "        plt.ylabel('빈도')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(domain_log['mean'], kde=True)\n",
    "        plt.title(f'{domain} 도메인 - 로그 변환 데이터 평균 분포')\n",
    "        plt.xlabel('값 (로그 스케일)')\n",
    "        plt.ylabel('빈도')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 샘플 시계열 데이터 변환 전/후 비교\n",
    "        sample_id = sample_series_ids[domain]\n",
    "        \n",
    "        # 원본 시계열 데이터\n",
    "        orig_start_time, orig_values = domain_time_series[domain][sample_id]\n",
    "        # 로그 변환된 시계열 데이터\n",
    "        log_start_time, log_values = log_transformed_series[domain][sample_id]\n",
    "        \n",
    "        # NaN이 아닌 값만 사용하여 시각화\n",
    "        valid_indices = ~np.isnan(orig_values)\n",
    "        valid_orig_values = np.array(orig_values)[valid_indices]\n",
    "        valid_log_values = np.array(log_values)[valid_indices]\n",
    "        time_indices = np.arange(len(valid_orig_values))\n",
    "        \n",
    "        # 변환 전후 차이를 더 명확하게 보여주는 시각화\n",
    "        fig = plt.figure(figsize=(15, 12))\n",
    "        gs = GridSpec(3, 2, figure=fig)\n",
    "        \n",
    "        # 원본 데이터\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        ax1.plot(time_indices, valid_orig_values, 'b-')\n",
    "        ax1.set_title(f'{domain} 도메인 샘플 시계열 (ID: {sample_id}) - 원본 데이터')\n",
    "        ax1.set_ylabel('값')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # 로그 변환 데이터\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        ax2.plot(time_indices, valid_log_values, 'r-')\n",
    "        ax2.set_title(f'{domain} 도메인 샘플 시계열 (ID: {sample_id}) - 로그 변환 데이터')\n",
    "        ax2.set_ylabel('로그 값')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        # 쌍축 그래프 (같은 그래프에 두 데이터 표시)\n",
    "        ax3 = fig.add_subplot(gs[1, :])\n",
    "        line1 = ax3.plot(time_indices, valid_orig_values, 'b-', label='원본 데이터')\n",
    "        ax3.set_ylabel('원본 값', color='b')\n",
    "        ax3.tick_params(axis='y', labelcolor='b')\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        ax3_twin = ax3.twinx()\n",
    "        line2 = ax3_twin.plot(time_indices, valid_log_values, 'r-', label='로그 변환 데이터')\n",
    "        ax3_twin.set_ylabel('로그 값', color='r')\n",
    "        ax3_twin.tick_params(axis='y', labelcolor='r')\n",
    "        \n",
    "        # 범례 추가\n",
    "        lines = line1 + line2\n",
    "        labels = [l.get_label() for l in lines]\n",
    "        ax3.legend(lines, labels, loc='upper right')\n",
    "        ax3.set_title('원본 vs 로그 변환 (쌍축 - 스케일 차이 확인)')\n",
    "        \n",
    "        # 데이터 분포 비교\n",
    "        ax4 = fig.add_subplot(gs[2, 0])\n",
    "        ax4.hist(valid_orig_values, bins=20, alpha=0.7, color='b')\n",
    "        ax4.set_title('원본 데이터 분포')\n",
    "        ax4.set_xlabel('값')\n",
    "        ax4.set_ylabel('빈도')\n",
    "        ax4.grid(True)\n",
    "        \n",
    "        ax5 = fig.add_subplot(gs[2, 1])\n",
    "        ax5.hist(valid_log_values, bins=20, alpha=0.7, color='r')\n",
    "        ax5.set_title('로그 변환 데이터 분포')\n",
    "        ax5.set_xlabel('로그 값')\n",
    "        ax5.set_ylabel('빈도')\n",
    "        ax5.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 변동성 패턴 비교 (이동 표준편차)\n",
    "        if len(valid_orig_values) > 10:  # 충분한 데이터가 있는 경우에만\n",
    "            window_size = max(5, len(valid_orig_values) // 10)  # 적절한 윈도우 크기 설정\n",
    "            \n",
    "            # 이동 표준편차 계산\n",
    "            rolling_std_orig = []\n",
    "            rolling_std_log = []\n",
    "            \n",
    "            for i in range(len(valid_orig_values) - window_size + 1):\n",
    "                rolling_std_orig.append(np.std(valid_orig_values[i:i+window_size]))\n",
    "                rolling_std_log.append(np.std(valid_log_values[i:i+window_size]))\n",
    "                \n",
    "            # 변동성 정규화 (비교를 위해)\n",
    "            if np.mean(rolling_std_orig) > 0 and np.mean(rolling_std_log) > 0:\n",
    "                norm_std_orig = np.array(rolling_std_orig) / np.mean(rolling_std_orig)\n",
    "                norm_std_log = np.array(rolling_std_log) / np.mean(rolling_std_log)\n",
    "                \n",
    "                plt.figure(figsize=(15, 6))\n",
    "                plt.plot(range(len(norm_std_orig)), norm_std_orig, 'b-', \n",
    "                         label='원본 데이터 정규화된 이동 표준편차')\n",
    "                plt.plot(range(len(norm_std_log)), norm_std_log, 'r-', \n",
    "                         label='로그 변환 데이터 정규화된 이동 표준편차')\n",
    "                plt.title('시간에 따른 변동성 비교 (정규화된 이동 표준편차)')\n",
    "                plt.xlabel('시간 인덱스')\n",
    "                plt.ylabel('정규화된 표준편차')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "    \n",
    "    # 전체 도메인 변환 전후 왜도 비교\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    skew_comparison = pd.DataFrame({\n",
    "        'domain': domains,\n",
    "        'original_skew': [original_df[original_df['domain'] == d]['skewness'].mean() for d in domains],\n",
    "        'log_skew': [log_df[log_df['domain'] == d]['skewness'].mean() for d in domains]\n",
    "    })\n",
    "    \n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(domains))\n",
    "    \n",
    "    plt.bar(x - bar_width/2, skew_comparison['original_skew'], bar_width, label='원본 데이터')\n",
    "    plt.bar(x + bar_width/2, skew_comparison['log_skew'], bar_width, label='로그 변환 데이터')\n",
    "    \n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.xticks(x, domains)\n",
    "    plt.title('도메인별 평균 왜도 비교 (변환 전후)')\n",
    "    plt.xlabel('도메인')\n",
    "    plt.ylabel('평균 왜도')\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "    return log_transformed_series, combined_df\n",
    "\n",
    "# 함수 실행\n",
    "log_transformed_series, transformation_stats = apply_log_transformation(domain_time_series)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "log_transformed_series"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "def apply_and_visualize_differencing(domain_time_series, domain, ts_id=None):\n",
    "    \"\"\"\n",
    "    특정 도메인의 시계열 데이터에 다양한 차분을 적용하고 시각화합니다:\n",
    "    1. 1차 차분\n",
    "    2. 2차 차분\n",
    "    3. 계절 차분(4 주기)\n",
    "    4. 계절 차분 + 1차 차분\n",
    "    5. 계절 차분 + 2차 차분\n",
    "    \n",
    "    각 단계별로 ADF 및 KPSS 정상성 검정을 수행합니다.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "    from statsmodels.tsa.stattools import adfuller, kpss\n",
    "    from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "    import warnings\n",
    "    \n",
    "    # 경고 숨기기\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # 도메인에서 시계열 선택\n",
    "    if ts_id is None:\n",
    "        ts_id = random.choice(list(domain_time_series[domain].keys()))\n",
    "    \n",
    "    start_time, values = domain_time_series[domain][ts_id]\n",
    "    values_np = np.array(values)\n",
    "    \n",
    "    # 결측값 처리\n",
    "    mask = ~np.isnan(values_np)\n",
    "    values_clean = values_np[mask]\n",
    "    \n",
    "    # 값이 너무 적으면 다른 시계열 선택\n",
    "    if len(values_clean) < 10:\n",
    "        print(f\"시계열 {ts_id}의 유효 데이터가 너무 적습니다. 다른 시계열을 선택하세요.\")\n",
    "        return None\n",
    "    \n",
    "    # pandas Series로 변환 (날짜 인덱스 포함)\n",
    "    if isinstance(start_time, str):\n",
    "        start_time = pd.to_datetime(start_time)\n",
    "    \n",
    "    # 인덱스가 중요하지 않다면 정수 인덱스로 대체 가능\n",
    "    original_series = pd.Series(values_clean)\n",
    "    \n",
    "    # 차분 적용\n",
    "    # 1. 1차 차분\n",
    "    diff1 = original_series.diff().dropna()\n",
    "    \n",
    "    # 2. 2차 차분\n",
    "    diff2 = diff1.diff().dropna()\n",
    "    \n",
    "    # 3. 계절 차분 (4 주기)\n",
    "    if len(original_series) > 4:  # 계절 차분을 위한 최소 길이 확인\n",
    "        seasonal_diff = original_series.diff(periods=4).dropna()\n",
    "    else:\n",
    "        seasonal_diff = pd.Series([])  # 빈 시리즈 생성\n",
    "    \n",
    "    # 4. 계절 차분 + 1차 차분\n",
    "    if len(seasonal_diff) > 1:\n",
    "        seasonal_diff1 = seasonal_diff.diff().dropna()\n",
    "    else:\n",
    "        seasonal_diff1 = pd.Series([])\n",
    "    \n",
    "    # 5. 계절 차분 + 2차 차분\n",
    "    if len(seasonal_diff1) > 1:\n",
    "        seasonal_diff2 = seasonal_diff1.diff().dropna()\n",
    "    else:\n",
    "        seasonal_diff2 = pd.Series([])\n",
    "    \n",
    "    # 차분 적용 결과 시각화\n",
    "    fig, axes = plt.subplots(6, 1, figsize=(14, 18), sharex=True)\n",
    "    \n",
    "    # 원본 시계열\n",
    "    original_series.plot(ax=axes[0], title=f'원본 시계열 ({domain} 도메인, {ts_id})')\n",
    "    axes[0].set_ylabel('값')\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # 1차 차분\n",
    "    if len(diff1) > 0:\n",
    "        diff1.plot(ax=axes[1], title=f'1차 차분')\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, \"데이터 부족으로 계산 불가\", ha='center', va='center')\n",
    "    axes[1].set_ylabel('1차 차분 값')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # 2차 차분\n",
    "    if len(diff2) > 0:\n",
    "        diff2.plot(ax=axes[2], title=f'2차 차분')\n",
    "    else:\n",
    "        axes[2].text(0.5, 0.5, \"데이터 부족으로 계산 불가\", ha='center', va='center')\n",
    "    axes[2].set_ylabel('2차 차분 값')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    # 계절 차분 (4 주기)\n",
    "    if len(seasonal_diff) > 0:\n",
    "        seasonal_diff.plot(ax=axes[3], title=f'계절 차분 (4 주기)')\n",
    "    else:\n",
    "        axes[3].text(0.5, 0.5, \"데이터 부족으로 계산 불가\", ha='center', va='center')\n",
    "    axes[3].set_ylabel('계절 차분 값')\n",
    "    axes[3].grid(True)\n",
    "    \n",
    "    # 계절 차분 + 1차 차분\n",
    "    if len(seasonal_diff1) > 0:\n",
    "        seasonal_diff1.plot(ax=axes[4], title=f'계절 차분 + 1차 차분')\n",
    "    else:\n",
    "        axes[4].text(0.5, 0.5, \"데이터 부족으로 계산 불가\", ha='center', va='center')\n",
    "    axes[4].set_ylabel('계절 + 1차 차분 값')\n",
    "    axes[4].grid(True)\n",
    "    \n",
    "    # 계절 차분 + 2차 차분\n",
    "    if len(seasonal_diff2) > 0:\n",
    "        seasonal_diff2.plot(ax=axes[5], title=f'계절 차분 + 2차 차분')\n",
    "    else:\n",
    "        axes[5].text(0.5, 0.5, \"데이터 부족으로 계산 불가\", ha='center', va='center')\n",
    "    axes[5].set_ylabel('계절 + 2차 차분 값')\n",
    "    axes[5].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 정상성 검정 함수\n",
    "    def run_stationarity_tests(series, name):\n",
    "        print(f\"\\n=== {name} 정상성 검정 ===\")\n",
    "        \n",
    "        if len(series) < 8:  # 테스트에 필요한 최소 데이터 길이\n",
    "            print(f\"데이터 길이가 충분하지 않아 검정을 수행할 수 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # ADF 검정\n",
    "            adf_result = adfuller(series.dropna())\n",
    "            print(f\"ADF 검정 결과:\")\n",
    "            print(f'  ADF 통계량: {adf_result[0]:.4f}')\n",
    "            print(f'  p-value: {adf_result[1]:.4f}')\n",
    "            print(f'  정상성 여부: {\"정상\" if adf_result[1] < 0.05 else \"비정상\"}')\n",
    "        except:\n",
    "            print(\"ADF 검정 실패 - 시계열 특성이나 길이 문제일 수 있습니다.\")\n",
    "        \n",
    "        try:\n",
    "            # KPSS 검정\n",
    "            kpss_result = kpss(series.dropna())\n",
    "            print(f\"KPSS 검정 결과:\")\n",
    "            print(f'  KPSS 통계량: {kpss_result[0]:.4f}')\n",
    "            print(f'  p-value: {kpss_result[1]:.4f}')\n",
    "            print(f'  정상성 여부: {\"정상\" if kpss_result[1] > 0.05 else \"비정상\"}')\n",
    "        except:\n",
    "            print(\"KPSS 검정 실패 - 시계열 특성이나 길이 문제일 수 있습니다.\")\n",
    "    \n",
    "    # 각 시계열에 대한 정상성 검정\n",
    "    run_stationarity_tests(original_series, \"원본 시계열\")\n",
    "    run_stationarity_tests(diff1, \"1차 차분\")\n",
    "    run_stationarity_tests(diff2, \"2차 차분\")\n",
    "    run_stationarity_tests(seasonal_diff, \"계절 차분\")\n",
    "    run_stationarity_tests(seasonal_diff1, \"계절 차분 + 1차 차분\")\n",
    "    run_stationarity_tests(seasonal_diff2, \"계절 차분 + 2차 차분\")\n",
    "    \n",
    "    # 각 시계열의 ACF/PACF 시각화\n",
    "    fig, axes = plt.subplots(6, 2, figsize=(15, 24))\n",
    "    \n",
    "    # 차분별 시계열 및 이름 목록\n",
    "    series_list = [\n",
    "        (original_series, \"원본 시계열\"),\n",
    "        (diff1, \"1차 차분\"),\n",
    "        (diff2, \"2차 차분\"),\n",
    "        (seasonal_diff, \"계절 차분\"),\n",
    "        (seasonal_diff1, \"계절 차분 + 1차 차분\"),\n",
    "        (seasonal_diff2, \"계절 차분 + 2차 차분\")\n",
    "    ]\n",
    "    \n",
    "    # 각 시계열에 대한 ACF/PACF 시각화\n",
    "    for i, (series, name) in enumerate(series_list):\n",
    "        if len(series) > 3:  # ACF/PACF에 필요한 최소 데이터 길이 확인\n",
    "            try:\n",
    "                # ACF 플롯\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    plot_acf(series.dropna(), lags=min(48, len(series) // 2), ax=axes[i, 0])\n",
    "                axes[i, 0].set_title(f'{name} ACF')\n",
    "                \n",
    "                # PACF 플롯\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    plot_pacf(series.dropna(), lags=min(48, len(series) // 2), ax=axes[i, 1])\n",
    "                axes[i, 1].set_title(f'{name} PACF')\n",
    "            except:\n",
    "                axes[i, 0].text(0.5, 0.5, f\"ACF 계산 실패\", ha='center', va='center')\n",
    "                axes[i, 1].text(0.5, 0.5, f\"PACF 계산 실패\", ha='center', va='center')\n",
    "        else:\n",
    "            axes[i, 0].text(0.5, 0.5, f\"데이터 부족으로 계산 불가\", ha='center', va='center')\n",
    "            axes[i, 1].text(0.5, 0.5, f\"데이터 부족으로 계산 불가\", ha='center', va='center')\n",
    "        \n",
    "        axes[i, 0].set_title(f'{name} ACF')\n",
    "        axes[i, 1].set_title(f'{name} PACF')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 결과 시계열 반환\n",
    "    return {\n",
    "        \"domain\": domain,\n",
    "        \"ts_id\": ts_id,\n",
    "        \"original\": original_series,\n",
    "        \"diff1\": diff1,\n",
    "        \"diff2\": diff2,\n",
    "        \"seasonal_diff\": seasonal_diff,\n",
    "        \"seasonal_diff1\": seasonal_diff1,\n",
    "        \"seasonal_diff2\": seasonal_diff2\n",
    "    }\n",
    "\n",
    "# 각 도메인별로 시계열 하나씩 선택하여 차분 분석 실행\n",
    "def analyze_domain_differencing(domain_time_series):\n",
    "    \"\"\"\n",
    "    각 도메인별로 시계열 하나씩 선택하여 차분 분석을 수행합니다.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    differencing_results = {}\n",
    "    \n",
    "    for domain in domain_time_series.keys():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"도메인: {domain} 차분 분석\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # 각 도메인에서 데이터 길이가 충분한 시계열 찾기\n",
    "        valid_ts_ids = []\n",
    "        for ts_id, (_, values) in domain_time_series[domain].items():\n",
    "            if sum(~np.isnan(values)) >= 20:  # 최소 20개의 유효한 데이터 포인트 필요\n",
    "                valid_ts_ids.append(ts_id)\n",
    "        \n",
    "        if not valid_ts_ids:\n",
    "            print(f\"{domain} 도메인에 충분한 데이터를 가진 시계열이 없습니다.\")\n",
    "            continue\n",
    "        \n",
    "        # 충분한 데이터를 가진 시계열 중 랜덤하게 선택\n",
    "        ts_id = random.choice(valid_ts_ids)\n",
    "        \n",
    "        # 선택된 시계열에 대해 차분 분석 수행\n",
    "        result = apply_and_visualize_differencing(domain_time_series, domain, ts_id)\n",
    "        if result:\n",
    "            differencing_results[domain] = result\n",
    "        \n",
    "    return differencing_results\n",
    "\n",
    "# 모든 도메인에 대해 차분 분석 실행\n",
    "all_domain_differencing = analyze_domain_differencing(log_transformed_series)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수동 파라미터 선정\n",
    "\n",
    "MACRO: SARIMA(2,1,1)(0,1,0)4  \n",
    "MICRO: SARIMA(2,1,1)(0,1,0)4  \n",
    "DEMOGRAPHIC: SARIMA(0,1,0)(0,0,0)4  \n",
    "INDUSTRY: SARIMA(0,1,0)(0,1,2)4  \n",
    "FINANCE: SARIMA(2,2,1)(0,0,0)4  \n",
    "OTHER: SARIMA(0,2,1)(1,0,1)4  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적의 파라미터 찾기 (20개 랜덤, 그리드 서치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import ast\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesResampler\n",
    "from pmdarima.arima import ARIMA\n",
    "\n",
    "def grid_search_sarima(time_series, m=4):\n",
    "    \"\"\"\n",
    "    주어진 시계열 데이터에 대해 후보 ARIMA 파라미터 조합에 따른 그리드 서치를 수행하고,\n",
    "    각 후보 조합과 AIC 값을 출력한 후, 가장 낮은 AIC 값을 가진 파라미터 조합을 반환.\n",
    "    \n",
    "    후보 범위:\n",
    "      - p: 0, 1, 2\n",
    "      - d: 0, 1\n",
    "      - q: 0, 1, 2\n",
    "      - P: 0, 1\n",
    "      - D: 0, 1\n",
    "      - Q: 0, 1\n",
    "      - m: 고정 (여기서는 4)\n",
    "      \n",
    "    Returns:\n",
    "      best_order (tuple), best_seasonal_order (tuple), best_aic (float)\n",
    "    \"\"\"\n",
    "    p_values = [0, 1, 2]\n",
    "    d_values = [0, 1]\n",
    "    q_values = [0, 1, 2]\n",
    "    P_values = [0, 1]\n",
    "    D_values = [0, 1]\n",
    "    Q_values = [0, 1]\n",
    "\n",
    "    best_aic = np.inf\n",
    "    best_order = None\n",
    "    best_seasonal_order = None\n",
    "\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                for P in P_values:\n",
    "                    for D in D_values:\n",
    "                        for Q in Q_values:\n",
    "                            order = (p, d, q)\n",
    "                            seasonal_order = (P, D, Q, m)\n",
    "                            try:\n",
    "                                model = ARIMA(order=order, seasonal_order=seasonal_order).fit(time_series)\n",
    "                                candidate_aic = model.aic()\n",
    "                                print(f\"Candidate ARIMA{order}x{seasonal_order} -> AIC: {candidate_aic:.2f}\")\n",
    "                                if candidate_aic < best_aic:\n",
    "                                    best_aic = candidate_aic\n",
    "                                    best_order = order\n",
    "                                    best_seasonal_order = seasonal_order\n",
    "                            except Exception as e:\n",
    "                                continue\n",
    "    return best_order, best_seasonal_order, best_aic\n",
    "\n",
    "# --- 최종 클러스터링 결과에 초기 파라미터를 할당하는 함수 (재사용) ---\n",
    "def assign_fixed_parameters_to_clusters(cluster_ids, best_order, best_seasonal_order):\n",
    "    \"\"\"\n",
    "    클러스터별로, 미리 선정된 초기 파라미터(best_order, best_seasonal_order)를\n",
    "    각 군집에 할당하는 함수.\n",
    "    \n",
    "    Returns:\n",
    "      dict: 각 클러스터별 초기 파라미터와 군집에 속한 시계열 ID 목록.\n",
    "    \"\"\"\n",
    "    cluster_params = {}\n",
    "    for cluster, ids in cluster_ids.items():\n",
    "        cluster_params[cluster] = {\n",
    "            'order': best_order,\n",
    "            'seasonal_order': best_seasonal_order,\n",
    "            'num_series': len(ids),\n",
    "            'sample_ids': ids[:5]\n",
    "        }\n",
    "    return cluster_params\n",
    "\n",
    "# =============================================================================\n",
    "# 실행 코드 블럭: 도메인별 그룹화, 클러스터링, 각 군집별 그리드 서치를 통한 초기 파라미터 선정,\n",
    "# 그리고 최종 결과 도출\n",
    "# =============================================================================\n",
    "\n",
    "domain_results = {}\n",
    "for domain, ts_dict in log_transformed_series.items():\n",
    "    print(f\"\\n========== 도메인: {domain} ==========\")\n",
    "\n",
    "    # 먼저 도메인 전체에 대해 DTW 기반 클러스터링을 수행하여 군집을 구분\n",
    "    domain_series = []\n",
    "    domain_ids = []\n",
    "    for ts_id, (start_time, values) in ts_dict.items():\n",
    "        if len(values) >= 8:\n",
    "            domain_series.append(values)\n",
    "            domain_ids.append(ts_id)\n",
    "    domain_initial_length = int(np.median([len(s) for s in domain_series]))\n",
    "    resampler_domain = TimeSeriesResampler(sz=domain_initial_length)\n",
    "    X_domain = resampler_domain.fit_transform(domain_series)\n",
    "    clustering_model = TimeSeriesKMeans(n_clusters=3, metric=\"dtw\", max_iter=10, random_state=42, verbose=True)\n",
    "    y_domain = clustering_model.fit_predict(X_domain)\n",
    "    clusters = defaultdict(list)\n",
    "    cluster_ids = defaultdict(list)\n",
    "    for ts_id, cluster in zip(domain_ids, y_domain):\n",
    "        clusters[cluster].append(ts_dict[ts_id])\n",
    "        cluster_ids[cluster].append(ts_id)\n",
    "    for cluster in clusters:\n",
    "        print(f\"클러스터 {cluster}: {len(clusters[cluster])}개 시계열\")\n",
    "\n",
    "    # 각 군집별로 랜덤 샘플 20개(20개 미만이면 전체)를 선택하여, \n",
    "    # grid search를 수행하고 그 결과 중 AIC가 가장 낮은 파라미터를 해당 군집의 초기 파라미터로 결정\n",
    "    cluster_initial_params = {}  # 각 군집별 초기 파라미터 저장\n",
    "    for cluster in clusters:\n",
    "        cluster_data = clusters[cluster]\n",
    "        id_list = cluster_ids[cluster]\n",
    "        if len(cluster_data) >= 20:\n",
    "            sample_indices = np.random.choice(range(len(cluster_data)), size=20, replace=False)\n",
    "        else:\n",
    "            sample_indices = list(range(len(cluster_data)))\n",
    "        print(f\"\\n클러스터 {cluster}에서 {len(sample_indices)}개 샘플 선택 (전체 {len(cluster_data)}개)\")\n",
    "\n",
    "        best_cluster_aic = np.inf\n",
    "        best_cluster_order = None\n",
    "        best_cluster_seasonal_order = None\n",
    "        # 각 샘플에 대해 grid search 수행\n",
    "        for idx in sample_indices:\n",
    "            ts_sample = cluster_data[idx][1]  # (start_timestamp, values)\n",
    "            print(f\"샘플 {id_list[idx]}에 대한 그리드 서치:\")\n",
    "            order_candidate, seasonal_candidate, aic_candidate = grid_search_sarima(ts_sample, m=4)\n",
    "            print(f\"  후보: ARIMA{order_candidate}x{seasonal_candidate} -> AIC: {aic_candidate:.2f}\")\n",
    "            if aic_candidate < best_cluster_aic:\n",
    "                best_cluster_aic = aic_candidate\n",
    "                best_cluster_order = order_candidate\n",
    "                best_cluster_seasonal_order = seasonal_candidate\n",
    "        print(f\"클러스터 {cluster} 최종 초기 파라미터: ARIMA{best_cluster_order}x{best_cluster_seasonal_order} (AIC: {best_cluster_aic:.2f})\")\n",
    "        cluster_initial_params[cluster] = {\n",
    "            'order': best_cluster_order,\n",
    "            'seasonal_order': best_cluster_seasonal_order,\n",
    "            'best_aic': best_cluster_aic\n",
    "        }\n",
    "\n",
    "    # 최종적으로, 각 클러스터에 대해 선정된 초기 파라미터를 할당\n",
    "    fixed_params = assign_fixed_parameters_to_clusters(cluster_ids,\n",
    "                                                       best_order=cluster_initial_params[0]['order'] if 0 in cluster_initial_params else None,\n",
    "                                                       best_seasonal_order=cluster_initial_params[0]['seasonal_order'] if 0 in cluster_initial_params else None)\n",
    "    # (예시로 클러스터 0의 파라미터를 할당했지만, 실제로는 각 클러스터별로 따로 저장되어야 함)\n",
    "    # 여기서는 각 군집별로 최적 파라미터를 별도로 저장하는 dictionary를 생성합니다.\n",
    "    fixed_params = {}\n",
    "    for cluster, params in cluster_initial_params.items():\n",
    "        fixed_params[cluster] = {\n",
    "            'order': params['order'],\n",
    "            'seasonal_order': params['seasonal_order'],\n",
    "            'num_series': len(cluster_ids[cluster]),\n",
    "            'sample_ids': cluster_ids[cluster][:5]\n",
    "        }\n",
    "    domain_results[domain] = {\n",
    "        'cluster_params': fixed_params,\n",
    "        'ts_cluster_map': {ts_id: cluster for cluster, ids in cluster_ids.items() for ts_id in ids}\n",
    "    }\n",
    "\n",
    "# 최종 결과 출력: 도메인별 초기 SARIMA 파라미터 요약\n",
    "print(\"\\n=== 도메인별 초기 SARIMA 파라미터 최종 결과 ===\")\n",
    "for domain, res in domain_results.items():\n",
    "    print(f\"\\n도메인 {domain}:\")\n",
    "    for cluster, params in res['cluster_params'].items():\n",
    "        print(f\"  클러스터 {cluster}: {params}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "domain_results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T03:36:17.845225Z",
     "start_time": "2025-03-14T03:36:16.970825Z"
    }
   },
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import os\n",
    "import pickle\n",
    "import gc  # 가비지 컬렉션 모듈 추가\n",
    "import logging\n",
    "\n",
    "# 시계열 예측 모델들\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from prophet import Prophet\n",
    "from tbats import TBATS\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# 평가 지표\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# 경고 제외\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# matplotlib 설정\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# 결과 저장 디렉토리\n",
    "RESULTS_DIR = './model_results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# 도메인별 SARIMA 파라미터 설정\n",
    "DOMAIN_SARIMA_PARAMS = {\n",
    "    'Macro': {'order': (2, 1, 1), 'seasonal_order': (0, 1, 0, 4)},\n",
    "    'Micro': {'order': (2, 1, 1), 'seasonal_order': (0, 1, 0, 4)},\n",
    "    'Demographic': {'order': (0, 1, 0), 'seasonal_order': (0, 0, 0, 4)},\n",
    "    'Industry': {'order': (0, 1, 0), 'seasonal_order': (0, 1, 2, 4)},\n",
    "    'Finance': {'order': (2, 2, 1), 'seasonal_order': (0, 0, 0, 4)},\n",
    "    'Other': {'order': (0, 2, 1), 'seasonal_order': (1, 0, 1, 4)},\n",
    "    'unknown': {'order': (2, 1, 1), 'seasonal_order': (1, 1, 1, 4)}  # 기본값\n",
    "}\n",
    "\n",
    "# Theta 모델 구현 (statsmodels에서 직접 제공하지 않음)\n",
    "def theta_model(y, h=48):\n",
    "    \"\"\"\n",
    "    Theta 모델 구현\n",
    "    \n",
    "    Parameters:\n",
    "    y (array-like): 입력 시계열 데이터\n",
    "    h (int): 예측할 기간 수\n",
    "    \n",
    "    Returns:\n",
    "    array: 예측값 배열\n",
    "    \"\"\"\n",
    "    y = np.asarray(y)\n",
    "    n = len(y)\n",
    "    \n",
    "    # 시계열 분해\n",
    "    t = np.arange(1, n+1)\n",
    "    X = np.column_stack((np.ones(n), t))\n",
    "    beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    \n",
    "    # 추세 성분 및 잔차 추출\n",
    "    trend = X @ beta\n",
    "    resid = y - trend\n",
    "    \n",
    "    # SES를 사용한 잔차 예측\n",
    "    ses_model = SimpleExpSmoothing(resid).fit(optimized=True)\n",
    "    resid_forecast = ses_model.forecast(h)\n",
    "    \n",
    "    # 추세 예측\n",
    "    t_new = np.arange(n+1, n+h+1)\n",
    "    X_new = np.column_stack((np.ones(h), t_new))\n",
    "    trend_forecast = X_new @ beta\n",
    "    \n",
    "    # 최종 예측: 추세 + 잔차\n",
    "    forecast = trend_forecast + resid_forecast\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "# 메모리 사용량 최적화를 위한 함수\n",
    "def optimize_result_memory(result):\n",
    "    \"\"\"결과 객체에서 메모리를 많이 차지하는 부분 최적화\"\"\"\n",
    "    if 'results' in result:\n",
    "        for model_name, model_info in result['results'].items():\n",
    "            # 모델 객체 제거 (예측에 필요 없음)\n",
    "            if 'model' in model_info:\n",
    "                model_info['model'] = None\n",
    "            \n",
    "            # forecast 데이터를 numpy에서 list로 변환 (더 효율적)\n",
    "            if 'forecast' in model_info and hasattr(model_info['forecast'], 'tolist'):\n",
    "                model_info['forecast'] = model_info['forecast'].tolist()\n",
    "    return result\n",
    "\n",
    "# 모델 성능 평가 함수\n",
    "def evaluate_forecast(actual, predicted, naive_forecast=None):\n",
    "    \"\"\"\n",
    "    예측 성능 평가\n",
    "    \n",
    "    Parameters:\n",
    "    actual (array-like): 실제 값\n",
    "    predicted (array-like): 예측 값\n",
    "    naive_forecast (array-like, optional): 단순 예측 값 (OWA 계산용)\n",
    "    \n",
    "    Returns:\n",
    "    dict: 평가 지표\n",
    "    \"\"\"\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    # 결측값 처리\n",
    "    mask = ~np.isnan(actual) & ~np.isnan(predicted)\n",
    "    actual = actual[mask]\n",
    "    predicted = predicted[mask]\n",
    "    \n",
    "    # 모든 값이 0인 경우 처리\n",
    "    if len(actual) == 0 or len(predicted) == 0:\n",
    "        return {\n",
    "            'smape': np.nan,\n",
    "            'mase': np.nan,\n",
    "            'owa': np.nan\n",
    "        }\n",
    "    \n",
    "    # sMAPE 계산\n",
    "    smape = np.mean(200.0 * np.abs(actual - predicted) / (np.abs(actual) + np.abs(predicted))) if np.any(np.abs(actual) + np.abs(predicted) > 0) else np.nan\n",
    "    \n",
    "    # MASE 계산 (naive 예측: t-1 시점의 값을 사용)\n",
    "    # 훈련 데이터에 대한 정보가 없으므로 단순화된 버전 사용\n",
    "    if len(actual) >= 2:\n",
    "        naive_errors = np.abs(np.diff(actual))\n",
    "        mean_naive_error = np.mean(naive_errors) if len(naive_errors) > 0 else np.inf\n",
    "        if mean_naive_error > 0:\n",
    "            mase = np.mean(np.abs(actual - predicted)) / mean_naive_error\n",
    "        else:\n",
    "            mase = np.nan\n",
    "    else:\n",
    "        mase = np.nan\n",
    "    \n",
    "    # OWA 계산 (M4 경진대회 지표: sMAPE와 MASE의 평균)\n",
    "    # OWA = 0.5 * (sMAPE / sMAPE_naive + MASE)\n",
    "    # 여기서는 단순화하여 OWA = 0.5 * (smape + mase)로 계산\n",
    "    if not np.isnan(smape) and not np.isnan(mase):\n",
    "        owa = 0.5 * (smape + mase)\n",
    "    else:\n",
    "        owa = np.nan\n",
    "    \n",
    "    return {\n",
    "        'smape': smape,\n",
    "        'mase': mase,\n",
    "        'owa': owa\n",
    "    }\n",
    "\n",
    "# 각 모델 구현\n",
    "class ForecastingModels:\n",
    "    def __init__(self, train_data, test_data, seasonal_period=4, ts_id=None, optimal_params=None, domain=None):\n",
    "        \"\"\"\n",
    "        예측 모델 클래스\n",
    "        \n",
    "        Parameters:\n",
    "        train_data (pd.Series): 훈련 데이터\n",
    "        test_data (pd.Series): 테스트 데이터\n",
    "        seasonal_period (int): 계절성 주기 (기본값: 4)\n",
    "        ts_id (str): 시계열 ID (클러스터링 기반 SARIMA용)\n",
    "        optimal_params (dict): 도메인별 클러스터 SARIMA 파라미터 결과\n",
    "        domain (str): 시계열이 속한 도메인\n",
    "        \"\"\"\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.h = len(test_data)\n",
    "        self.seasonal_period = seasonal_period\n",
    "        self.ts_id = ts_id\n",
    "        self.optimal_params = optimal_params\n",
    "        self.domain = domain\n",
    "        self.results = {}\n",
    "    \n",
    "    def fit_ses(self):\n",
    "        \"\"\"Simple Exponential Smoothing\"\"\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            model = SimpleExpSmoothing(self.train_data).fit(optimized=True)\n",
    "            forecast = model.forecast(self.h)\n",
    "            aic = model.aic if hasattr(model, 'aic') else np.nan\n",
    "            bic = model.bic if hasattr(model, 'bic') else np.nan\n",
    "            \n",
    "            metrics = evaluate_forecast(self.test_data, forecast)\n",
    "            metrics.update({'aic': aic, 'bic': bic})\n",
    "            \n",
    "            self.results['SES'] = {\n",
    "                'forecast': forecast,\n",
    "                'metrics': metrics,\n",
    "                'model': model,\n",
    "                'time': time.time() - start_time\n",
    "            }\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"SES 모델 오류: {e}\")\n",
    "            self.results['SES'] = {\n",
    "                'forecast': np.array([np.nan] * self.h),\n",
    "                'metrics': {k: np.nan for k in ['smape', 'mase', 'owa', 'aic', 'bic']},\n",
    "                'model': None,\n",
    "                'time': time.time() - start_time,\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return False\n",
    "    \n",
    "    def fit_theta(self):\n",
    "        \"\"\"Theta 모델\"\"\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            forecast = theta_model(self.train_data.values, h=self.h)\n",
    "            \n",
    "            metrics = evaluate_forecast(self.test_data, forecast)\n",
    "            # Theta 모델은 AIC/BIC가 없음\n",
    "            metrics.update({'aic': np.nan, 'bic': np.nan})\n",
    "            \n",
    "            self.results['Theta'] = {\n",
    "                'forecast': forecast,\n",
    "                'metrics': metrics,\n",
    "                'model': None,  # Theta 모델은 별도의 모델 객체가 없음\n",
    "                'time': time.time() - start_time\n",
    "            }\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Theta 모델 오류: {e}\")\n",
    "            self.results['Theta'] = {\n",
    "                'forecast': np.array([np.nan] * self.h),\n",
    "                'metrics': {k: np.nan for k in ['smape', 'mase', 'owa', 'aic', 'bic']},\n",
    "                'model': None,\n",
    "                'time': time.time() - start_time,\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return False\n",
    "    \n",
    "    def fit_tbats(self):\n",
    "        \"\"\"TBATS 모델\"\"\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # TBATS 모델은 계산 비용이 높으므로 시간 제한 설정\n",
    "            model = TBATS(seasonal_periods=[self.seasonal_period], \n",
    "                         use_arma_errors=False,  # 단순화를 위해 ARMA 오차 사용 안함\n",
    "                         use_box_cox=False)      # 단순화를 위해 Box-Cox 변환 사용 안함\n",
    "            \n",
    "            fitted_model = model.fit(self.train_data.values)\n",
    "            forecast = fitted_model.forecast(steps=self.h)\n",
    "            \n",
    "            metrics = evaluate_forecast(self.test_data, forecast)\n",
    "            # TBATS는 AIC만 제공\n",
    "            metrics.update({\n",
    "                'aic': fitted_model.aic if hasattr(fitted_model, 'aic') else np.nan,\n",
    "                'bic': np.nan\n",
    "            })\n",
    "            \n",
    "            self.results['TBATS'] = {\n",
    "                'forecast': forecast,\n",
    "                'metrics': metrics,\n",
    "                'model': fitted_model,\n",
    "                'time': time.time() - start_time\n",
    "            }\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"TBATS 모델 오류: {e}\")\n",
    "            self.results['TBATS'] = {\n",
    "                'forecast': np.array([np.nan] * self.h),\n",
    "                'metrics': {k: np.nan for k in ['smape', 'mase', 'owa', 'aic', 'bic']},\n",
    "                'model': None,\n",
    "                'time': time.time() - start_time,\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return False\n",
    "    \n",
    "    def fit_hw_ets(self):\n",
    "        \"\"\"Holt-Winters Exponential Smoothing\"\"\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            model = ExponentialSmoothing(\n",
    "                self.train_data, \n",
    "                seasonal_periods=self.seasonal_period, \n",
    "                trend='add', \n",
    "                seasonal='add',\n",
    "                use_boxcox=False  # 단순화를 위해 Box-Cox 변환 사용 안함\n",
    "            ).fit(optimized=True)\n",
    "            \n",
    "            forecast = model.forecast(self.h)\n",
    "            \n",
    "            metrics = evaluate_forecast(self.test_data, forecast)\n",
    "            metrics.update({\n",
    "                'aic': model.aic if hasattr(model, 'aic') else np.nan,\n",
    "                'bic': model.bic if hasattr(model, 'bic') else np.nan\n",
    "            })\n",
    "            \n",
    "            self.results['HW_ETS'] = {\n",
    "                'forecast': forecast,\n",
    "                'metrics': metrics,\n",
    "                'model': model,\n",
    "                'time': time.time() - start_time\n",
    "            }\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Holt-Winters 모델 오류: {e}\")\n",
    "            self.results['HW_ETS'] = {\n",
    "                'forecast': np.array([np.nan] * self.h),\n",
    "                'metrics': {k: np.nan for k in ['smape', 'mase', 'owa', 'aic', 'bic']},\n",
    "                'model': None,\n",
    "                'time': time.time() - start_time,\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return False\n",
    "    \n",
    "    def fit_sarima(self):\n",
    "        \"\"\"도메인별 최적 파라미터를 사용한 SARIMA 모델\"\"\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # 도메인별 SARIMA 파라미터 가져오기\n",
    "            domain_params = DOMAIN_SARIMA_PARAMS.get(self.domain, DOMAIN_SARIMA_PARAMS['unknown'])\n",
    "            order = domain_params['order']\n",
    "            seasonal_order = domain_params['seasonal_order']\n",
    "            \n",
    "            # SARIMA 모델 적합\n",
    "            model = SARIMAX(\n",
    "                self.train_data,\n",
    "                order=order,             # 도메인별 설정된 비계절 부분: (p, d, q)\n",
    "                seasonal_order=seasonal_order, # 도메인별 설정된 계절 부분: (P, D, Q, s)\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            \n",
    "            fitted_model = model.fit(disp=False, maxiter=50, method='lbfgs')\n",
    "            forecast = fitted_model.get_forecast(steps=self.h).predicted_mean\n",
    "            \n",
    "            metrics = evaluate_forecast(self.test_data, forecast)\n",
    "            metrics.update({\n",
    "                'aic': fitted_model.aic if hasattr(fitted_model, 'aic') else np.nan,\n",
    "                'bic': fitted_model.bic if hasattr(fitted_model, 'bic') else np.nan,\n",
    "                'order': str(order),\n",
    "                'seasonal_order': str(seasonal_order)\n",
    "            })\n",
    "            \n",
    "            self.results['SARIMA'] = {\n",
    "                'forecast': forecast,\n",
    "                'metrics': metrics,\n",
    "                'model': fitted_model,\n",
    "                'time': time.time() - start_time,\n",
    "                'sarima_info': {\n",
    "                    'domain': self.domain,\n",
    "                    'order': order,\n",
    "                    'seasonal_order': seasonal_order\n",
    "                }\n",
    "            }\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"SARIMA 모델 오류: {e}\")\n",
    "            self.results['SARIMA'] = {\n",
    "                'forecast': np.array([np.nan] * self.h),\n",
    "                'metrics': {k: np.nan for k in ['smape', 'mase', 'owa', 'aic', 'bic']},\n",
    "                'model': None,\n",
    "                'time': time.time() - start_time,\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return False\n",
    "    \n",
    "    def fit_cluster_sarima(self):\n",
    "        \"\"\"클러스터링 기반 SARIMA 모델\"\"\"\n",
    "        if self.optimal_params is None or self.ts_id is None or self.domain is None:\n",
    "            return False\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # 도메인이 optimal_params에 존재하는지 확인\n",
    "            if self.domain in self.optimal_params:\n",
    "                ts_cluster_map = self.optimal_params[self.domain]['ts_cluster_map']\n",
    "                cluster_params = self.optimal_params[self.domain]['cluster_params']\n",
    "                \n",
    "                if self.ts_id in ts_cluster_map:\n",
    "                    cluster = ts_cluster_map[self.ts_id]\n",
    "                    if cluster in cluster_params:\n",
    "                        # 클러스터별 최적 파라미터 가져오기\n",
    "                        order = cluster_params[cluster]['order']\n",
    "                        seasonal_order = cluster_params[cluster]['seasonal_order']\n",
    "                        \n",
    "                        # 모델 학습 및 예측\n",
    "                        model = SARIMAX(\n",
    "                            self.train_data, \n",
    "                            order=order, \n",
    "                            seasonal_order=seasonal_order,\n",
    "                            enforce_stationarity=False,\n",
    "                            enforce_invertibility=False\n",
    "                        )\n",
    "                        \n",
    "                        fitted_model = model.fit(disp=False, maxiter=50, method='lbfgs')\n",
    "                        forecast = fitted_model.get_forecast(steps=self.h).predicted_mean\n",
    "                        \n",
    "                        metrics = evaluate_forecast(self.test_data, forecast)\n",
    "                        metrics.update({\n",
    "                            'aic': fitted_model.aic if hasattr(fitted_model, 'aic') else np.nan,\n",
    "                            'bic': fitted_model.bic if hasattr(fitted_model, 'bic') else np.nan,\n",
    "                            'cluster': cluster,\n",
    "                            'domain': self.domain\n",
    "                        })\n",
    "                        \n",
    "                        self.results['ClusterSARIMA'] = {\n",
    "                            'forecast': forecast,\n",
    "                            'metrics': metrics,\n",
    "                            'model': fitted_model,\n",
    "                            'time': time.time() - start_time,\n",
    "                            'cluster_info': {\n",
    "                                'domain': self.domain,\n",
    "                                'cluster': cluster,\n",
    "                                'order': order,\n",
    "                                'seasonal_order': seasonal_order\n",
    "                            }\n",
    "                        }\n",
    "                        return True\n",
    "            \n",
    "            # 도메인이나 클러스터를 찾을 수 없는 경우 도메인별 기본 SARIMA 사용\n",
    "            domain_params = DOMAIN_SARIMA_PARAMS.get(self.domain, DOMAIN_SARIMA_PARAMS['unknown'])\n",
    "            order = domain_params['order']\n",
    "            seasonal_order = domain_params['seasonal_order']\n",
    "            \n",
    "            model = SARIMAX(\n",
    "                self.train_data,\n",
    "                order=order,\n",
    "                seasonal_order=seasonal_order,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            \n",
    "            fitted_model = model.fit(disp=False, maxiter=50, method='lbfgs')\n",
    "            forecast = fitted_model.get_forecast(steps=self.h).predicted_mean\n",
    "            \n",
    "            metrics = evaluate_forecast(self.test_data, forecast)\n",
    "            metrics.update({\n",
    "                'aic': fitted_model.aic if hasattr(fitted_model, 'aic') else np.nan,\n",
    "                'bic': fitted_model.bic if hasattr(fitted_model, 'bic') else np.nan,\n",
    "                'cluster': 'unknown',\n",
    "                'domain': self.domain\n",
    "            })\n",
    "            \n",
    "            self.results['ClusterSARIMA'] = {\n",
    "                'forecast': forecast,\n",
    "                'metrics': metrics,\n",
    "                'model': fitted_model,\n",
    "                'time': time.time() - start_time,\n",
    "                'cluster_info': {\n",
    "                    'domain': self.domain,\n",
    "                    'cluster': 'unknown',\n",
    "                    'order': order,\n",
    "                    'seasonal_order': seasonal_order\n",
    "                }\n",
    "            }\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"클러스터 SARIMA 모델 오류: {e}\")\n",
    "            self.results['ClusterSARIMA'] = {\n",
    "                'forecast': np.array([np.nan] * self.h),\n",
    "                'metrics': {k: np.nan for k in ['smape', 'mase', 'owa', 'aic', 'bic']},\n",
    "                'model': None,\n",
    "                'time': time.time() - start_time,\n",
    "                'error': str(e),\n",
    "                'cluster_info': {\n",
    "                    'domain': self.domain,\n",
    "                    'cluster': 'error'\n",
    "                }\n",
    "            }\n",
    "            return False\n",
    "    \n",
    "    def fit_prophet(self):\n",
    "        \"\"\"Prophet 모델\"\"\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # Prophet용 데이터프레임 준비\n",
    "            df = pd.DataFrame({\n",
    "                'ds': self.train_data.index,\n",
    "                'y': self.train_data.values\n",
    "            })\n",
    "            \n",
    "            model = Prophet(\n",
    "                daily_seasonality=True,\n",
    "                yearly_seasonality=False,\n",
    "                weekly_seasonality=True,\n",
    "                seasonality_mode='additive'\n",
    "            )\n",
    "            \n",
    "            model.fit(df)\n",
    "            \n",
    "            # 예측 기간 준비\n",
    "            future = model.make_future_dataframe(periods=self.h, freq='h')\n",
    "            forecast_df = model.predict(future)\n",
    "            \n",
    "            # 테스트 기간에 해당하는 예측값 추출\n",
    "            forecast = forecast_df.iloc[-self.h:]['yhat'].values\n",
    "            \n",
    "            metrics = evaluate_forecast(self.test_data, forecast)\n",
    "            # Prophet은 AIC/BIC가 없음\n",
    "            metrics.update({'aic': np.nan, 'bic': np.nan})\n",
    "            \n",
    "            self.results['Prophet'] = {\n",
    "                'forecast': forecast,\n",
    "                'metrics': metrics,\n",
    "                'model': model,\n",
    "                'time': time.time() - start_time\n",
    "            }\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Prophet 모델 오류: {e}\")\n",
    "            self.results['Prophet'] = {\n",
    "                'forecast': np.array([np.nan] * self.h),\n",
    "                'metrics': {k: np.nan for k in ['smape', 'mase', 'owa', 'aic', 'bic']},\n",
    "                'model': None,\n",
    "                'time': time.time() - start_time,\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return False\n",
    "    \n",
    "    def fit_all_models(self, optimize_memory=True, exclude_heavy_models=False, include_cluster_sarima=False):\n",
    "        \"\"\"\n",
    "        모든 모델 학습 및 평가\n",
    "        \n",
    "        Parameters:\n",
    "        optimize_memory (bool): 메모리 사용량 최적화 여부\n",
    "        exclude_heavy_models (bool): 무거운 모델(Prophet, TBATS)을 제외할지 여부\n",
    "        include_cluster_sarima (bool): 클러스터링 기반 SARIMA 모델 포함 여부\n",
    "        \n",
    "        Returns:\n",
    "        dict: 모델 결과 딕셔너리\n",
    "        \"\"\"\n",
    "        self.fit_ses()\n",
    "        self.fit_theta()\n",
    "        \n",
    "        if not exclude_heavy_models:\n",
    "            self.fit_tbats()\n",
    "        \n",
    "        self.fit_hw_ets()\n",
    "        self.fit_sarima()\n",
    "        \n",
    "        if include_cluster_sarima:\n",
    "            self.fit_cluster_sarima()\n",
    "        \n",
    "        if not exclude_heavy_models:\n",
    "            self.fit_prophet()\n",
    "        \n",
    "        # 메모리 최적화 - 큰 모델 객체 제거\n",
    "        if optimize_memory:\n",
    "            for model_name, model_info in self.results.items():\n",
    "                if 'model' in model_info:\n",
    "                    # 모델 객체는 결과 분석에 필요 없으므로 제거\n",
    "                    model_info['model'] = None\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "def evaluate_time_series(ts_id, domain, log_transformed_series, test_size=8, seasonal_period=4, \n",
    "                        optimize_memory=True, exclude_heavy_models=False, \n",
    "                        optimal_params=None, include_cluster_sarima=False):\n",
    "    \"\"\"\n",
    "    단일 시계열에 대해 모든 모델 평가 (로그 변환된 데이터 사용)\n",
    "    \n",
    "    Parameters:\n",
    "    ts_id (str): 시계열 ID\n",
    "    domain (str): 시계열이 속한 도메인\n",
    "    log_transformed_series (dict): 로그 변환된 시계열 데이터 딕셔너리\n",
    "    test_size (int): 테스트 세트 크기\n",
    "    seasonal_period (int): 계절성 주기 (기본값: 4)\n",
    "    optimize_memory (bool): 메모리 사용량 최적화 여부\n",
    "    exclude_heavy_models (bool): 무거운 모델 제외 여부\n",
    "    optimal_params (dict): 도메인별 클러스터 SARIMA 파라미터\n",
    "    include_cluster_sarima (bool): 클러스터링 기반 SARIMA 모델 포함 여부\n",
    "    \n",
    "    Returns:\n",
    "    dict: 모델 평가 결과\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 로그 변환된 시계열 데이터 가져오기\n",
    "        if domain not in log_transformed_series or ts_id not in log_transformed_series[domain]:\n",
    "            return {\n",
    "                'ts_id': ts_id,\n",
    "                'domain': domain,\n",
    "                'error': f\"시계열 {domain}/{ts_id}가 로그 변환 데이터에 없습니다.\"\n",
    "            }\n",
    "        \n",
    "        start_time, values = log_transformed_series[domain][ts_id]\n",
    "        \n",
    "        # 결측치 제거된 값 배열 생성\n",
    "        values_clean = np.array([v for v in values if not np.isnan(v)])\n",
    "        \n",
    "        # 시계열 생성\n",
    "        if isinstance(start_time, str):\n",
    "            start_time = pd.to_datetime(start_time)\n",
    "        \n",
    "        date_range = pd.date_range(start=start_time, periods=len(values_clean), freq='h')\n",
    "        series = pd.Series(values_clean, index=date_range)\n",
    "        \n",
    "        # 훈련/테스트 세트 분할\n",
    "        if len(series) <= test_size:\n",
    "            return {\n",
    "                'ts_id': ts_id,\n",
    "                'domain': domain,\n",
    "                'error': f\"시계열 {ts_id}의 길이({len(series)})가 테스트 크기({test_size})보다 작습니다.\"\n",
    "            }\n",
    "            \n",
    "        train_size = len(series) - test_size\n",
    "        train_data = series[:train_size]\n",
    "        test_data = series[train_size:]\n",
    "        \n",
    "        # 모델 학습 및 평가\n",
    "        models = ForecastingModels(\n",
    "            train_data, test_data, \n",
    "            seasonal_period=seasonal_period,\n",
    "            ts_id=ts_id,\n",
    "            optimal_params=optimal_params,\n",
    "            domain=domain\n",
    "        )\n",
    "        \n",
    "        results = models.fit_all_models(\n",
    "            optimize_memory=optimize_memory, \n",
    "            exclude_heavy_models=exclude_heavy_models,\n",
    "            include_cluster_sarima=include_cluster_sarima\n",
    "        )\n",
    "        \n",
    "        result_dict = {\n",
    "            'ts_id': ts_id,\n",
    "            'domain': domain,\n",
    "            'results': results,\n",
    "            'train_data': train_data,\n",
    "            'test_data': test_data\n",
    "        }\n",
    "        \n",
    "        # 메모리 최적화\n",
    "        if optimize_memory:\n",
    "            # 훈련/테스트 데이터를 numpy 배열로 변환하여 메모리 사용량 감소\n",
    "            result_dict['train_data'] = train_data.values\n",
    "            result_dict['test_data'] = test_data.values\n",
    "        \n",
    "        return result_dict\n",
    "    except Exception as e:\n",
    "        print(f\"시계열 {domain}/{ts_id} 평가 중 오류 발생: {e}\")\n",
    "        return {\n",
    "            'ts_id': ts_id,\n",
    "            'domain': domain,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# 모델 결과 요약 함수\n",
    "def summarize_model_results(all_results):\n",
    "    \"\"\"\n",
    "    모든 시계열에 대한 모델 결과 요약\n",
    "    \n",
    "    Parameters:\n",
    "    all_results (list): 각 시계열의 모델 결과 리스트\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: 요약 데이터프레임\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for ts_result in all_results:\n",
    "        if 'error' in ts_result:\n",
    "            continue\n",
    "        \n",
    "        ts_id = ts_result['ts_id']\n",
    "        domain = ts_result.get('domain', 'unknown')  # 도메인 정보 추가\n",
    "        results = ts_result['results']\n",
    "        \n",
    "        for model_name, model_result in results.items():\n",
    "            metrics = model_result['metrics']\n",
    "            execution_time = model_result['time']\n",
    "            \n",
    "            row = {\n",
    "                'ts_id': ts_id,\n",
    "                'domain': domain,  # 도메인 정보 추가\n",
    "                'model': model_name,\n",
    "                'smape': metrics['smape'],\n",
    "                'mase': metrics['mase'],\n",
    "                'owa': metrics['owa'],\n",
    "                'aic': metrics['aic'],\n",
    "                'bic': metrics['bic'],\n",
    "                'execution_time': execution_time\n",
    "            }\n",
    "            \n",
    "            # SARIMA 모델인 경우 파라미터 정보 추가\n",
    "            if model_name == 'SARIMA' and 'sarima_info' in model_result:\n",
    "                row['order'] = str(model_result['sarima_info'].get('order', ''))\n",
    "                row['seasonal_order'] = str(model_result['sarima_info'].get('seasonal_order', ''))\n",
    "                \n",
    "            # 클러스터 SARIMA 모델인 경우 클러스터 정보 추가\n",
    "            # 클러스터 SARIMA 모델인 경우 클러스터 정보 추가\n",
    "            if model_name == 'ClusterSARIMA' and 'cluster_info' in model_result:\n",
    "                row['cluster'] = model_result['cluster_info'].get('cluster', 'unknown')\n",
    "                row['order'] = str(model_result['cluster_info'].get('order', ''))\n",
    "                row['seasonal_order'] = str(model_result['cluster_info'].get('seasonal_order', ''))\n",
    "                \n",
    "            summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    return summary_df\n",
    "\n",
    "# 개별 시계열에 대한 모델 예측 시각화 함수 개선\n",
    "def visualize_forecast_with_intervals(ts_id, ts_result, log_transformed_series=None):\n",
    "   \"\"\"\n",
    "   개별 시계열에 대한 모델 예측을 시각화하고 가능한 경우 신뢰구간 추가\n",
    "   \n",
    "   Parameters:\n",
    "   ts_id (str): 시계열 ID\n",
    "   ts_result (dict): 시계열 평가 결과\n",
    "   log_transformed_series (dict, optional): 로그 변환된 시계열 데이터 딕셔너리\n",
    "   \"\"\"\n",
    "   # 한글 폰트 설정 - 이 함수 내에서만 적용\n",
    "   import matplotlib as mpl\n",
    "   import matplotlib.font_manager as fm\n",
    "   import platform\n",
    "   \n",
    "   # 스타일 설정\n",
    "   plt.style.use('seaborn-v0_8-whitegrid')\n",
    "   \n",
    "   # 시스템별 폰트 설정\n",
    "   system_name = platform.system()\n",
    "   if system_name == \"Windows\":\n",
    "       plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "   elif system_name == \"Darwin\":  # macOS\n",
    "       plt.rcParams['font.family'] = 'AppleGothic'\n",
    "   else:  # Linux 등\n",
    "       # 범용 폰트 사용\n",
    "       plt.rcParams['font.family'] = 'NanumGothic, DejaVu Sans'\n",
    "   \n",
    "   # 마이너스 기호 깨짐 방지\n",
    "   mpl.rcParams['axes.unicode_minus'] = False\n",
    "   \n",
    "   if not ts_result or 'error' in ts_result:\n",
    "       print(f\"시계열 {ts_id}에 대한 결과가 없거나 오류가 있습니다.\")\n",
    "       return\n",
    "       \n",
    "   train_data = ts_result['train_data']\n",
    "   test_data = ts_result['test_data']\n",
    "   results = ts_result['results']\n",
    "   domain = ts_result.get('domain', 'unknown')  # 도메인 정보 추가\n",
    "   \n",
    "   # 데이터가 numpy 배열인 경우 Series로 변환\n",
    "   if isinstance(train_data, np.ndarray):\n",
    "       # 원본 데이터의 시작 시간 가져오기 (가능한 경우)\n",
    "       start_time = datetime(2015, 1, 1)  # 기본값\n",
    "       if log_transformed_series and domain in log_transformed_series and ts_id in log_transformed_series[domain]:\n",
    "           start_time = log_transformed_series[domain][ts_id][0]\n",
    "           if isinstance(start_time, str):\n",
    "               start_time = pd.to_datetime(start_time)\n",
    "           \n",
    "       date_range = pd.date_range(start=start_time, periods=len(train_data), freq='h')\n",
    "       train_data = pd.Series(train_data, index=date_range)\n",
    "       test_data = pd.Series(test_data, index=pd.date_range(start=date_range[-1] + timedelta(hours=1), periods=len(test_data), freq='h'))\n",
    "   \n",
    "   # 그래프 설정\n",
    "   plt.figure(figsize=(16, 10))\n",
    "   \n",
    "   # 서브플롯 - 전체 데이터와 테스트 기간 확대뷰\n",
    "   fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12), gridspec_kw={'height_ratios': [2, 3]})\n",
    "   \n",
    "   # 1. 전체 데이터 뷰 (ax1)\n",
    "   # 원본 데이터\n",
    "   ax1.plot(train_data.index, train_data, label='훈련 데이터', color='black', linewidth=1.5, alpha=0.7)\n",
    "   ax1.plot(test_data.index, test_data, label='테스트 데이터', color='blue', linewidth=2)\n",
    "   \n",
    "   # 테스트 영역 표시\n",
    "   ax1.axvspan(test_data.index[0], test_data.index[-1], alpha=0.1, color='blue', label='테스트 구간')\n",
    "   \n",
    "   # 각 모델의 예측\n",
    "   # 시각적으로 더 구분하기 쉬운 색상 팔레트 사용\n",
    "   colors = plt.cm.Set2(np.linspace(0, 1, 8))  # 뚜렷하게 구분되는 색상 팔레트\n",
    "   \n",
    "   # 신뢰구간을 표시할 모델 (일반적으로 SARIMA와 Prophet은 신뢰구간 제공)\n",
    "   models_with_intervals = ['SARIMA', 'ClusterSARIMA', 'Prophet']\n",
    "   \n",
    "   for i, (model_name, model_result) in enumerate(results.items()):\n",
    "       forecast = model_result['forecast']\n",
    "       metrics = model_result['metrics']\n",
    "       \n",
    "       # forecast가 리스트인 경우 numpy 배열로 변환\n",
    "       if isinstance(forecast, list):\n",
    "           forecast = np.array(forecast)\n",
    "       \n",
    "       color = colors[i % len(colors)]\n",
    "       linestyle = ['-', '--', '-.', ':'][i % 4]  # 다양한 선 스타일 사용\n",
    "       \n",
    "       # 모델 이름과 성능 지표를 포함한 범례\n",
    "       label = f'{model_name} (OWA: {metrics[\"owa\"]:.2f})'\n",
    "       \n",
    "       ax1.plot(test_data.index, forecast, \n",
    "                label=label, \n",
    "                color=color, linewidth=2, linestyle=linestyle)\n",
    "   \n",
    "   ax1.set_title(f'시계열 {ts_id} - {domain} 도메인 - 전체 데이터 및 예측', fontsize=16)  # 도메인 정보 추가\n",
    "   ax1.set_xlabel('시간', fontsize=12)\n",
    "   ax1.set_ylabel('로그 값', fontsize=12)  # 로그 변환 데이터임을 표시\n",
    "   ax1.legend(loc='best', fontsize=10)\n",
    "   ax1.grid(True, alpha=0.3)\n",
    "   \n",
    "   # 2. 테스트 기간 확대뷰 (ax2)\n",
    "   # 테스트 기간 + 약간의 여백\n",
    "   padding = len(test_data) // 4  # 테스트 기간의 1/4만큼 여백\n",
    "   if padding > 0 and len(train_data) > padding:\n",
    "       start_idx = -padding - len(test_data)\n",
    "       ax2.plot(train_data.index[start_idx:], train_data.iloc[start_idx:], \n",
    "               label='훈련 데이터', color='black', linewidth=1.5, alpha=0.7)\n",
    "   else:\n",
    "       ax2.plot(train_data.index, train_data, \n",
    "               label='훈련 데이터', color='black', linewidth=1.5, alpha=0.7)\n",
    "   \n",
    "   ax2.plot(test_data.index, test_data, label='테스트 데이터', color='blue', linewidth=2.5)\n",
    "   \n",
    "   # 테스트 구간 경계선 표시\n",
    "   ax2.axvline(test_data.index[0], linestyle='--', color='blue', alpha=0.7)\n",
    "   \n",
    "   # 각 모델의 예측 및 신뢰구간 (가능한 경우)\n",
    "   for i, (model_name, model_result) in enumerate(results.items()):\n",
    "       forecast = model_result['forecast']\n",
    "       \n",
    "       # forecast가 리스트인 경우 numpy 배열로 변환\n",
    "       if isinstance(forecast, list):\n",
    "           forecast = np.array(forecast)\n",
    "       \n",
    "       color = colors[i % len(colors)]\n",
    "       linestyle = ['-', '--', '-.', ':'][i % 4]\n",
    "       \n",
    "       # 더 두꺼운 선으로 표시하여 구분 용이하게\n",
    "       ax2.plot(test_data.index, forecast, \n",
    "               color=color, linewidth=2.5, linestyle=linestyle,\n",
    "               label=f'{model_name} (OWA: {model_result[\"metrics\"][\"owa\"]:.2f})')\n",
    "       \n",
    "       # 신뢰구간 표시 (특정 모델에 대해)\n",
    "       if model_name in models_with_intervals:\n",
    "           try:\n",
    "               # SARIMA 모델 신뢰구간\n",
    "               if model_name in ['SARIMA', 'ClusterSARIMA']:\n",
    "                   # 모델 정보 가져오기\n",
    "                   if model_name == 'SARIMA' and 'sarima_info' in model_result:\n",
    "                       order = model_result['sarima_info'].get('order', (2, 1, 1))\n",
    "                       seasonal_order = model_result['sarima_info'].get('seasonal_order', (1, 1, 1, 4))\n",
    "                   elif model_name == 'ClusterSARIMA' and 'cluster_info' in model_result:\n",
    "                       order = model_result['cluster_info'].get('order', (2, 1, 1))\n",
    "                       seasonal_order = model_result['cluster_info'].get('seasonal_order', (1, 1, 1, 4))\n",
    "                   else:\n",
    "                       # 도메인별 기본값 사용\n",
    "                       domain_params = DOMAIN_SARIMA_PARAMS.get(domain, DOMAIN_SARIMA_PARAMS['unknown'])\n",
    "                       order = domain_params['order']\n",
    "                       seasonal_order = domain_params['seasonal_order']\n",
    "                   \n",
    "                   # 모델 재구성 및 신뢰구간 계산\n",
    "                   temp_model = SARIMAX(\n",
    "                       train_data,\n",
    "                       order=order,\n",
    "                       seasonal_order=seasonal_order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False\n",
    "                   ).fit(disp=False)\n",
    "                   \n",
    "                   forecast_obj = temp_model.get_forecast(steps=len(test_data))\n",
    "                   conf_int = forecast_obj.conf_int(alpha=0.05)  # 95% 신뢰구간\n",
    "                   \n",
    "                   # 신뢰구간 표시\n",
    "                   ax2.fill_between(test_data.index, \n",
    "                                   conf_int.iloc[:, 0], \n",
    "                                   conf_int.iloc[:, 1], \n",
    "                                   color=color, alpha=0.2)\n",
    "               \n",
    "               # Prophet 모델 신뢰구간 (별도로 계산)\n",
    "               elif model_name == 'Prophet':\n",
    "                   if 'forecast_df' in model_result and model_result['forecast_df'] is not None:\n",
    "                       # 저장된 forecast_df가 있는 경우\n",
    "                       prophet_forecast = model_result['forecast_df']\n",
    "                       ax2.fill_between(test_data.index,\n",
    "                                       prophet_forecast['yhat_lower'].values[-len(test_data):],\n",
    "                                       prophet_forecast['yhat_upper'].values[-len(test_data):],\n",
    "                                       color=color, alpha=0.2)\n",
    "                   else:\n",
    "                       # 없는 경우 근사적 계산\n",
    "                       residuals = test_data.values - forecast\n",
    "                       std_resid = np.std(residuals)\n",
    "                       z_value = 1.96  # 95% 신뢰수준의 z값\n",
    "                       \n",
    "                       lower_ci = forecast - z_value * std_resid\n",
    "                       upper_ci = forecast + z_value * std_resid\n",
    "                       \n",
    "                       ax2.fill_between(test_data.index,\n",
    "                                      lower_ci,\n",
    "                                      upper_ci,\n",
    "                                      color=color, alpha=0.2)\n",
    "           except Exception as e:\n",
    "               print(f\"{model_name} 모델 신뢰구간 계산 오류: {e}\")\n",
    "       \n",
    "       # 모든 모델에 대해 신뢰구간 계산 (신뢰구간이 없는 모델도 포함)\n",
    "       else:\n",
    "           try:\n",
    "               # 잔차 기반 근사적 신뢰구간 계산\n",
    "               residuals = test_data.values - forecast\n",
    "               std_resid = np.std(residuals)\n",
    "               z_value = 1.96  # 95% 신뢰수준의 z값\n",
    "               \n",
    "               lower_ci = forecast - z_value * std_resid\n",
    "               upper_ci = forecast + z_value * std_resid\n",
    "               \n",
    "               ax2.fill_between(test_data.index,\n",
    "                              lower_ci,\n",
    "                              upper_ci,\n",
    "                              color=color, alpha=0.2)\n",
    "           except Exception as e:\n",
    "               print(f\"{model_name} 근사 신뢰구간 계산 오류: {e}\")\n",
    "   \n",
    "   ax2.set_title(f'시계열 {ts_id} - {domain} 도메인 - 테스트 기간 확대', fontsize=16)  # 도메인 정보 추가\n",
    "   ax2.set_xlabel('시간', fontsize=12)\n",
    "   ax2.set_ylabel('로그 값', fontsize=12)  # 로그 변환 데이터임을 표시\n",
    "   \n",
    "   # 레이아웃 개선 - 더 명확한 범례\n",
    "   handles, labels = ax2.get_legend_handles_labels()\n",
    "   ax2.legend(handles, labels, loc='best', fontsize=10, framealpha=0.8, \n",
    "             bbox_to_anchor=(1, 1), title='모델 및 성능')\n",
    "   \n",
    "   ax2.grid(True, alpha=0.3)\n",
    "   \n",
    "   # 모델 간 더 명확한 비교를 위한 오차 표시\n",
    "   model_errors = {}\n",
    "   for model_name, model_result in results.items():\n",
    "       forecast = model_result['forecast']\n",
    "       \n",
    "       # forecast가 리스트인 경우 numpy 배열로 변환\n",
    "       if isinstance(forecast, list):\n",
    "           forecast = np.array(forecast)\n",
    "       \n",
    "       # 모델별 RMSE, MAE 계산\n",
    "       rmse = np.sqrt(np.mean((test_data.values - forecast) ** 2))\n",
    "       mae = np.mean(np.abs(test_data.values - forecast))\n",
    "       model_errors[model_name] = {'RMSE': rmse, 'MAE': mae}\n",
    "   \n",
    "   # 오차 정보를 텍스트로 표시\n",
    "   error_text = \"모델별 오차:\\n\"\n",
    "   for model, errors in sorted(model_errors.items(), key=lambda x: x[1]['RMSE']):\n",
    "       error_text += f\"{model}: RMSE={errors['RMSE']:.2f}, MAE={errors['MAE']:.2f}\\n\"\n",
    "   \n",
    "   plt.figtext(0.02, 0.02, error_text, fontsize=10, \n",
    "              bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(os.path.join(RESULTS_DIR, f'forecast_detailed_{domain}_{ts_id}.png'), dpi=150)  # 도메인 정보 추가\n",
    "   plt.show()\n",
    "\n",
    "   # 모델별 잔차 분석 그래프 - 추가적인 정보 제공\n",
    "   plt.figure(figsize=(16, 10))\n",
    "   fig, axes = plt.subplots(len(results), 1, figsize=(16, 4*len(results)))\n",
    "   \n",
    "   if len(results) == 1:\n",
    "       axes = [axes]  # 단일 모델 경우 리스트로 변환\n",
    "   \n",
    "   for i, (model_name, model_result) in enumerate(results.items()):\n",
    "       forecast = model_result['forecast']\n",
    "       \n",
    "       # forecast가 리스트인 경우 numpy 배열로 변환\n",
    "       if isinstance(forecast, list):\n",
    "           forecast = np.array(forecast)\n",
    "       \n",
    "       # 잔차 계산\n",
    "       residuals = test_data.values - forecast\n",
    "       \n",
    "       # 잔차 그래프\n",
    "       ax = axes[i]\n",
    "       ax.plot(test_data.index, residuals, marker='o', linestyle='None', \n",
    "              color=colors[i % len(colors)], alpha=0.7, markersize=4)\n",
    "       ax.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "       \n",
    "       # 이동 평균 추가\n",
    "       window = min(5, len(residuals) // 3) if len(residuals) > 5 else 1\n",
    "       if window > 1:\n",
    "           rolling_mean = pd.Series(residuals).rolling(window=window).mean()\n",
    "           ax.plot(test_data.index, rolling_mean, color='black', linewidth=2, \n",
    "                 label=f'{window}-포인트 이동 평균')\n",
    "       \n",
    "       ax.set_title(f'{model_name} 잔차', fontsize=14)\n",
    "       ax.set_ylabel('잔차 (실제 - 예측)', fontsize=10)\n",
    "       \n",
    "       # 잔차 통계 추가\n",
    "       mean_resid = np.mean(residuals)\n",
    "       std_resid = np.std(residuals)\n",
    "       \n",
    "       stats_text = f\"평균: {mean_resid:.2f}\\n표준편차: {std_resid:.2f}\"\n",
    "       ax.text(0.02, 0.90, stats_text, transform=ax.transAxes,\n",
    "              bbox=dict(facecolor='white', alpha=0.8))\n",
    "       \n",
    "       if window > 1:\n",
    "           ax.legend(loc='best')\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(os.path.join(RESULTS_DIR, f'residuals_{domain}_{ts_id}.png'), dpi=150)  # 도메인 정보 추가\n",
    "   plt.show()\n",
    "   \n",
    "   return fig\n",
    "\n",
    "# 결과 시각화 함수 업데이트\n",
    "def visualize_results(all_results, log_transformed_series=None, top_n=5):\n",
    "   \"\"\"\n",
    "   결과 시각화 - 개선된 시각화 적용\n",
    "   \n",
    "   Parameters:\n",
    "   all_results (list): 각 시계열의 모델 결과 리스트\n",
    "   log_transformed_series (dict): 로그 변환된 시계열 데이터 딕셔너리\n",
    "   top_n (int): 시각화할 상위 시계열 수\n",
    "   \"\"\"\n",
    "   summary_df = summarize_model_results(all_results)\n",
    "   \n",
    "   # 1. 모델별 평균 성능 비교 (전체 및 도메인별)\n",
    "   metrics = ['smape', 'mase', 'owa']\n",
    "   \n",
    "   # 전체 성능\n",
    "   plt.figure(figsize=(15, 15))\n",
    "   \n",
    "   for i, metric in enumerate(metrics):\n",
    "       plt.subplot(len(metrics), 1, i+1)\n",
    "       \n",
    "       model_avg = summary_df.groupby('model')[metric].mean().sort_values()\n",
    "       ax = sns.barplot(x=model_avg.index, y=model_avg.values, palette='viridis')\n",
    "       \n",
    "       # 값 표시 추가\n",
    "       for j, v in enumerate(model_avg.values):\n",
    "           ax.text(j, v + 0.01, f\"{v:.3f}\", ha='center', fontsize=10)\n",
    "       \n",
    "       plt.title(f'모델별 평균 {metric.upper()} (낮을수록 좋음)', fontsize=14)\n",
    "       plt.xlabel('모델', fontsize=12)\n",
    "       plt.ylabel(metric.upper(), fontsize=12)\n",
    "       plt.xticks(rotation=45)\n",
    "       plt.grid(True, alpha=0.3)\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(os.path.join(RESULTS_DIR, 'model_performance_comparison.png'), dpi=150)\n",
    "   plt.show()\n",
    "   \n",
    "   # 도메인별 성능 비교\n",
    "   for metric in metrics:\n",
    "       plt.figure(figsize=(15, 10))\n",
    "       \n",
    "       for i, domain in enumerate(summary_df['domain'].unique()):\n",
    "           domain_df = summary_df[summary_df['domain'] == domain]\n",
    "           model_avg = domain_df.groupby('model')[metric].mean().sort_values()\n",
    "           \n",
    "           plt.subplot(len(summary_df['domain'].unique()), 1, i+1)\n",
    "           ax = sns.barplot(x=model_avg.index, y=model_avg.values, palette='viridis')\n",
    "           \n",
    "           # 값 표시 추가\n",
    "           for j, v in enumerate(model_avg.values):\n",
    "               ax.text(j, v + 0.01, f\"{v:.3f}\", ha='center', fontsize=10)\n",
    "           \n",
    "           plt.title(f'{domain} 도메인 - 모델별 평균 {metric.upper()}', fontsize=14)\n",
    "           plt.xlabel('모델', fontsize=12)\n",
    "           plt.ylabel(metric.upper(), fontsize=12)\n",
    "           plt.xticks(rotation=45)\n",
    "           plt.grid(True, alpha=0.3)\n",
    "       \n",
    "       plt.tight_layout()\n",
    "       plt.savefig(os.path.join(RESULTS_DIR, f'domain_model_performance_{metric}.png'), dpi=150)\n",
    "       plt.show()\n",
    "   \n",
    "   # 2. 모델별 실행 시간 비교\n",
    "   plt.figure(figsize=(14, 10))\n",
    "   \n",
    "   # 2개의 서브플롯 생성 - 일반 스케일과 로그 스케일\n",
    "   fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "   \n",
    "   model_times = summary_df.groupby('model')['execution_time'].mean().sort_values()\n",
    "   \n",
    "   # 일반 스케일\n",
    "   sns.barplot(x=model_times.index, y=model_times.values, palette='magma', ax=ax1)\n",
    "   \n",
    "   # 값 표시 추가\n",
    "   for i, v in enumerate(model_times.values):\n",
    "       ax1.text(i, v + 0.1, f\"{v:.3f}초\", ha='center', fontsize=9)\n",
    "   \n",
    "   ax1.set_title('모델별 평균 실행 시간 (초)', fontsize=14)\n",
    "   ax1.set_xlabel('모델', fontsize=12)\n",
    "   ax1.set_ylabel('실행 시간 (초)', fontsize=12)\n",
    "   ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
    "   ax1.grid(True, alpha=0.3)\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(os.path.join(RESULTS_DIR, 'model_execution_times.png'), dpi=150)\n",
    "   plt.show()\n",
    "   \n",
    "   # 3. 개별 시계열에 대한 모델 예측 시각화 (도메인별 상위 N개 시계열)\n",
    "   # 도메인별로 상위 시계열 선택\n",
    "   for domain in summary_df['domain'].unique():\n",
    "       domain_df = summary_df[summary_df['domain'] == domain]\n",
    "       best_ts_ids = domain_df.groupby('ts_id')['owa'].min().sort_values()[:max(1, int(top_n/len(summary_df['domain'].unique())))].index\n",
    "       \n",
    "       for ts_id in best_ts_ids:\n",
    "           ts_result = next((r for r in all_results if r['ts_id'] == ts_id), None)\n",
    "           if not ts_result or 'error' in ts_result:\n",
    "               continue\n",
    "               \n",
    "           # 개선된 시각화 함수 호출\n",
    "           visualize_forecast_with_intervals(ts_id, ts_result, log_transformed_series)\n",
    "   \n",
    "   # 4. 박스플롯: 모델별 성능 분포 (도메인별)\n",
    "   for domain in summary_df['domain'].unique():\n",
    "       domain_df = summary_df[summary_df['domain'] == domain]\n",
    "       \n",
    "       plt.figure(figsize=(15, 15))\n",
    "       \n",
    "       for i, metric in enumerate(metrics):\n",
    "           plt.subplot(len(metrics), 1, i+1)\n",
    "           \n",
    "           sns.boxplot(x='model', y=metric, data=domain_df, palette='viridis')\n",
    "           \n",
    "           # 평균값 표시 추가\n",
    "           means = domain_df.groupby('model')[metric].mean()\n",
    "           pos = range(len(means))\n",
    "           for j, m in zip(pos, means):\n",
    "               plt.text(j, m, f\"{m:.3f}\", ha='center', va='bottom', fontsize=9, color='black')\n",
    "           \n",
    "           plt.title(f'{domain} 도메인 - 모델별 {metric.upper()} 분포', fontsize=14)\n",
    "           plt.xlabel('모델', fontsize=12)\n",
    "           plt.ylabel(metric.upper(), fontsize=12)\n",
    "           plt.xticks(rotation=45)\n",
    "           plt.grid(True, alpha=0.3)\n",
    "       \n",
    "       plt.tight_layout()\n",
    "       plt.savefig(os.path.join(RESULTS_DIR, f'model_performance_distributions_{domain}.png'), dpi=150)\n",
    "       plt.show()\n",
    "   \n",
    "   # 5. 클러스터 SARIMA와 일반 SARIMA 비교 (도메인별)\n",
    "   if 'ClusterSARIMA' in summary_df['model'].values and 'SARIMA' in summary_df['model'].values:\n",
    "       for domain in summary_df['domain'].unique():\n",
    "           domain_df = summary_df[summary_df['domain'] == domain]\n",
    "           sarima_models = domain_df[domain_df['model'].isin(['SARIMA', 'ClusterSARIMA'])]\n",
    "           \n",
    "           if len(sarima_models) > 0:\n",
    "               plt.figure(figsize=(12, 10))\n",
    "               \n",
    "               # 세 가지 성능 지표 비교\n",
    "               for i, metric in enumerate(['smape', 'mase', 'owa']):\n",
    "                   plt.subplot(3, 1, i+1)\n",
    "                   \n",
    "                   # 성능 분포 시각화\n",
    "                   sns.boxplot(x='model', y=metric, data=sarima_models, palette=['skyblue', 'lightgreen'])\n",
    "                   \n",
    "                   # 개별 데이터 포인트 추가 - 투명도 적용\n",
    "                   sns.stripplot(x='model', y=metric, data=sarima_models, color='black', alpha=0.3, size=3)\n",
    "                   \n",
    "                   # 평균값 표시 라인\n",
    "                   for j, model in enumerate(['SARIMA', 'ClusterSARIMA']):\n",
    "                       if model in sarima_models['model'].values:\n",
    "                           mean_val = sarima_models[sarima_models['model'] == model][metric].mean()\n",
    "                           plt.hlines(y=mean_val, xmin=j-0.3, xmax=j+0.3, colors='red', linestyles='dashed', linewidth=2)\n",
    "                           plt.text(j, mean_val, f\" 평균: {mean_val:.3f}\", ha='left', va='center', fontsize=9)\n",
    "                   \n",
    "                   plt.title(f'{domain} 도메인 - 일반 SARIMA vs 클러스터 SARIMA {metric.upper()} 비교', fontsize=14)\n",
    "                   plt.ylabel(metric.upper(), fontsize=12)\n",
    "                   plt.grid(True, alpha=0.3)\n",
    "               \n",
    "               plt.tight_layout()\n",
    "               plt.savefig(os.path.join(RESULTS_DIR, f'sarima_vs_cluster_sarima_{domain}.png'), dpi=150)\n",
    "               plt.show()\n",
    "               \n",
    "               # 클러스터별 ClusterSARIMA 성능 비교 (클러스터 정보가 있는 경우)\n",
    "               cluster_sarima = sarima_models[sarima_models['model'] == 'ClusterSARIMA']\n",
    "               \n",
    "               if len(cluster_sarima) > 0 and 'cluster' in cluster_sarima.columns and not cluster_sarima['cluster'].isna().all():\n",
    "                   plt.figure(figsize=(14, 10))\n",
    "                   \n",
    "                   # 각 클러스터별 시계열 개수 계산\n",
    "                   cluster_counts = cluster_sarima['cluster'].value_counts().sort_index()\n",
    "                   \n",
    "                   for i, metric in enumerate(['smape', 'mase', 'owa']):\n",
    "                       plt.subplot(3, 1, i+1)\n",
    "                       \n",
    "                       # 클러스터별 성능 분포\n",
    "                       ax = sns.boxplot(x='cluster', y=metric, data=cluster_sarima, palette='viridis')\n",
    "                       \n",
    "                       # 개별 데이터 포인트 추가\n",
    "                       sns.stripplot(x='cluster', y=metric, data=cluster_sarima, color='black', alpha=0.3, size=3)\n",
    "                       \n",
    "                       # 클러스터별 시계열 개수 표시\n",
    "                       for j, (cluster, count) in enumerate(cluster_counts.items()):\n",
    "                           if str(cluster) in [label.get_text() for label in ax.get_xticklabels()]:\n",
    "                               plt.text(j, ax.get_ylim()[1] * 0.95, f\"n={count}\", ha='center', va='top', fontsize=9)\n",
    "                       \n",
    "                       plt.title(f'{domain} 도메인 - 클러스터별 {metric.upper()} 성능 분포', fontsize=14)\n",
    "                       plt.xlabel('클러스터', fontsize=12)\n",
    "                       plt.ylabel(metric.upper(), fontsize=12)\n",
    "                       plt.grid(True, alpha=0.3)\n",
    "                   \n",
    "                   plt.tight_layout()\n",
    "                   plt.savefig(os.path.join(RESULTS_DIR, f'cluster_sarima_performance_{domain}.png'), dpi=150)\n",
    "                   plt.show()\n",
    "\n",
    "           # SARIMA와 ClusterSARIMA 비교 (둘 다 있는 경우)\n",
    "           sarima_df = domain_df[domain_df['model'] == 'SARIMA']\n",
    "           cluster_sarima_df = domain_df[domain_df['model'] == 'ClusterSARIMA']\n",
    "           \n",
    "           # 각 시계열별로 SARIMA와 ClusterSARIMA의 성능 차이 계산\n",
    "           ts_comparison = []\n",
    "           for ts_id in domain_df['ts_id'].unique():\n",
    "               ts_sarima = sarima_df[sarima_df['ts_id'] == ts_id]\n",
    "               ts_cluster = cluster_sarima_df[cluster_sarima_df['ts_id'] == ts_id]\n",
    "               \n",
    "               if len(ts_sarima) == 1 and len(ts_cluster) == 1:  # 두 모델 모두 있는 경우만 비교\n",
    "                   sarima_owa = ts_sarima['owa'].values[0]\n",
    "                   cluster_owa = ts_cluster['owa'].values[0]\n",
    "                   \n",
    "                   comparison = {\n",
    "                       'ts_id': ts_id,\n",
    "                       'domain': domain,\n",
    "                       'sarima_owa': sarima_owa,\n",
    "                       'cluster_owa': cluster_owa,\n",
    "                       'improvement': (sarima_owa - cluster_owa) / sarima_owa * 100,  # 개선율(%)\n",
    "                       'is_better': sarima_owa > cluster_owa  # ClusterSARIMA가 더 나은지 여부\n",
    "                   }\n",
    "                   \n",
    "                   # 클러스터 정보 추가\n",
    "                   if 'cluster' in ts_cluster.columns:\n",
    "                       comparison['cluster'] = ts_cluster['cluster'].values[0]\n",
    "                   \n",
    "                   ts_comparison.append(comparison)\n",
    "           \n",
    "           comparison_df = pd.DataFrame(ts_comparison)\n",
    "           \n",
    "           if not comparison_df.empty:\n",
    "               # 개선율 시각화\n",
    "               plt.figure(figsize=(14, 12))\n",
    "               \n",
    "               # 1. 개선율 분포 (히스토그램 + 커널 밀도)\n",
    "               plt.subplot(2, 1, 1)\n",
    "               \n",
    "               # 개선율 히스토그램에 컬러 구분 (양수: 개선, 음수: 악화)\n",
    "               improvement_data = comparison_df['improvement']\n",
    "               \n",
    "               # 양수 및 음수 값 분리\n",
    "               positive_mask = improvement_data >= 0\n",
    "               negative_mask = ~positive_mask\n",
    "               \n",
    "               # 히스토그램 + 커널 밀도 그래프\n",
    "               sns.histplot(improvement_data[positive_mask], kde=True, color='green', alpha=0.5, \n",
    "                          label='개선 (ClusterSARIMA가 우수)', bins=20)\n",
    "               sns.histplot(improvement_data[negative_mask], kde=True, color='red', alpha=0.5, \n",
    "                          label='악화 (SARIMA가 우수)', bins=20)\n",
    "               \n",
    "               # 0 지점에 수직선 추가\n",
    "               plt.axvline(x=0, color='black', linestyle='--', alpha=0.7)\n",
    "               \n",
    "               # 통계 정보 추가\n",
    "               better_pct = (comparison_df['is_better'].sum() / len(comparison_df)) * 100\n",
    "               mean_improvement = comparison_df['improvement'].mean()\n",
    "               median_improvement = comparison_df['improvement'].median()\n",
    "               \n",
    "               stats_text = (\n",
    "                   f\"ClusterSARIMA 우수 비율: {better_pct:.1f}%\\n\"\n",
    "                   f\"평균 개선율: {mean_improvement:.2f}%\\n\"\n",
    "                   f\"중앙값 개선율: {median_improvement:.2f}%\"\n",
    "               )\n",
    "               \n",
    "               plt.text(0.02, 0.85, stats_text, transform=plt.gca().transAxes,\n",
    "                      bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))\n",
    "               \n",
    "               plt.title(f'{domain} 도메인 - ClusterSARIMA의 SARIMA 대비 성능 개선율(%) 분포', fontsize=14)\n",
    "               plt.xlabel('개선율(%) (양수: ClusterSARIMA가 우수)', fontsize=12)\n",
    "               plt.ylabel('빈도', fontsize=12)\n",
    "               plt.legend(loc='upper right')\n",
    "               plt.grid(True, alpha=0.3)\n",
    "               \n",
    "               # 2. 클러스터별 개선율 (클러스터 정보가 있는 경우)\n",
    "               if 'cluster' in comparison_df.columns and len(comparison_df['cluster'].unique()) > 1:\n",
    "                   plt.subplot(2, 1, 2)\n",
    "                   \n",
    "                   # 클러스터별 개선율 박스플롯\n",
    "                   sns.boxplot(x='cluster', y='improvement', data=comparison_df, palette='viridis')\n",
    "                   \n",
    "                   # 개별 데이터 포인트 추가\n",
    "                   sns.stripplot(x='cluster', y='improvement', data=comparison_df, color='black', alpha=0.3, size=3)\n",
    "                   \n",
    "                   # 제로 라인 추가\n",
    "                   plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "                   \n",
    "                   # 클러스터별 개선율 평균 표시\n",
    "                   for i, cluster in enumerate(sorted(comparison_df['cluster'].unique())):\n",
    "                       cluster_data = comparison_df[comparison_df['cluster'] == cluster]\n",
    "                       mean_imp = cluster_data['improvement'].mean()\n",
    "                       better_pct = (cluster_data['is_better'].sum() / len(cluster_data)) * 100\n",
    "                       plt.text(i, mean_imp, f\"{mean_imp:.1f}%\\n({better_pct:.0f}% 우수)\", \n",
    "                              ha='center', va='center', fontsize=9,\n",
    "                              bbox=dict(facecolor='white', alpha=0.6, boxstyle='round,pad=0.2'))\n",
    "                   \n",
    "                   plt.title(f'{domain} 도메인 - 클러스터별 SARIMA 대비 성능 개선율', fontsize=14)\n",
    "                   plt.xlabel('클러스터', fontsize=12)\n",
    "                   plt.ylabel('개선율(%) (양수: ClusterSARIMA가 우수)', fontsize=12)\n",
    "                   plt.grid(True, alpha=0.3)\n",
    "               \n",
    "               plt.tight_layout()\n",
    "               plt.savefig(os.path.join(RESULTS_DIR, f'sarima_improvement_distribution_{domain}.png'), dpi=150)\n",
    "               plt.show()\n",
    "               \n",
    "               # 개선율 스캐터플롯 (SARIMA vs ClusterSARIMA)\n",
    "               plt.figure(figsize=(12, 10))\n",
    "               \n",
    "               plt.scatter(comparison_df['sarima_owa'], comparison_df['cluster_owa'], alpha=0.6,\n",
    "                          c=comparison_df['improvement'], cmap='RdYlGn', s=50)\n",
    "               \n",
    "               # 기준선 (x=y) 추가\n",
    "               lims = [\n",
    "                   min(plt.xlim()[0], plt.ylim()[0]),\n",
    "                   max(plt.xlim()[1], plt.ylim()[1])\n",
    "               ]\n",
    "               plt.plot(lims, lims, 'k--', alpha=0.5, label='동일 성능')\n",
    "               \n",
    "               # 컬러바 추가\n",
    "               cbar = plt.colorbar()\n",
    "               cbar.set_label('개선율 (%)', fontsize=12)\n",
    "               \n",
    "               plt.title(f'{domain} 도메인 - SARIMA vs ClusterSARIMA 성능 비교', fontsize=14)\n",
    "               plt.xlabel('SARIMA OWA', fontsize=12)\n",
    "               plt.ylabel('ClusterSARIMA OWA', fontsize=12)\n",
    "               plt.grid(True, alpha=0.3)\n",
    "               \n",
    "               # 개선/악화 영역 표시\n",
    "               plt.text(0.25, 0.8, \"ClusterSARIMA 우수\", transform=plt.gca().transAxes, \n",
    "                      fontsize=12, ha='center', rotation=-45, alpha=0.6)\n",
    "               plt.text(0.75, 0.2, \"SARIMA 우수\", transform=plt.gca().transAxes, \n",
    "                      fontsize=12, ha='center', rotation=-45, alpha=0.6)\n",
    "               \n",
    "               plt.tight_layout()\n",
    "               plt.savefig(os.path.join(RESULTS_DIR, f'sarima_vs_cluster_sarima_scatter_{domain}.png'), dpi=150)\n",
    "               plt.show()\n",
    "               \n",
    "               # 개선율 요약 통계\n",
    "               print(f\"\\n=== {domain} 도메인 - ClusterSARIMA의 SARIMA 대비 성능 개선율 요약 ===\")\n",
    "               print(f\"평균 개선율: {comparison_df['improvement'].mean():.2f}%\")\n",
    "               print(f\"중앙값 개선율: {comparison_df['improvement'].median():.2f}%\")\n",
    "               print(f\"최대 개선율: {comparison_df['improvement'].max():.2f}%\")\n",
    "               print(f\"최소 개선율: {comparison_df['improvement'].min():.2f}%\")\n",
    "               print(f\"ClusterSARIMA가 우수한 시계열 비율: {(comparison_df['improvement'] > 0).mean() * 100:.2f}%\")\n",
    "               \n",
    "               # 클러스터별 개선율 통계 (클러스터 정보가 있는 경우)\n",
    "               if 'cluster' in comparison_df.columns and len(comparison_df['cluster'].unique()) > 1:\n",
    "                   print(f\"\\n=== {domain} 도메인 - 클러스터별 개선율 통계 ===\")\n",
    "                   cluster_stats = comparison_df.groupby('cluster').agg({\n",
    "                       'improvement': ['mean', 'median', 'min', 'max', 'count'],\n",
    "                       'is_better': 'mean'  # 클러스터별 ClusterSARIMA가 우수한 비율\n",
    "                   })\n",
    "                   \n",
    "                   # 'is_better'의 평균을 퍼센트로 변환\n",
    "                   cluster_stats[('is_better', 'mean')] = cluster_stats[('is_better', 'mean')] * 100\n",
    "                   \n",
    "                   # 컬럼명 변경\n",
    "                   cluster_stats.columns = [\n",
    "                       '평균 개선율(%)', '중앙값 개선율(%)', '최소 개선율(%)', '최대 개선율(%)', \n",
    "                       '시계열 수', 'ClusterSARIMA 우수 비율(%)'\n",
    "                   ]\n",
    "                   \n",
    "                   print(cluster_stats.round(2))\n",
    "\n",
    "# 메인 함수\n",
    "def main(log_transformed_series, exclude_heavy_models=False, include_cluster_sarima=True, optimal_params=None):\n",
    "   start_time = time.time()\n",
    "\n",
    "   # 평가할 시계열 선택\n",
    "   all_ts_ids = []\n",
    "   for domain in log_transformed_series:\n",
    "       for ts_id in log_transformed_series[domain]:\n",
    "           all_ts_ids.append((domain, ts_id))\n",
    "   \n",
    "   print(f\"평가할 시계열: {len(all_ts_ids)}개\")\n",
    "   \n",
    "   # 시계열 ID가 없으면 종료\n",
    "   if len(all_ts_ids) == 0:\n",
    "       print(\"오류: 평가할 시계열이 없습니다. 프로그램을 종료합니다.\")\n",
    "       return\n",
    "   \n",
    "   # 각 시계열에 대해 모델 평가\n",
    "   print(\"모델 평가 중...\")\n",
    "   all_results = []\n",
    "\n",
    "   # 전체 시계열 수 계산\n",
    "   total_ts = len(all_ts_ids)\n",
    "   halfway_point = total_ts // 2  # 50% 지점\n",
    "\n",
    "   # tqdm으로 진행 상황 표시\n",
    "   from tqdm.auto import tqdm\n",
    "\n",
    "   # 시작 시간 기록\n",
    "   eval_start_time = time.time()\n",
    "\n",
    "   for i, (domain, ts_id) in enumerate(tqdm(all_ts_ids, \n",
    "                                        desc=\"시계열 평가\", \n",
    "                                        ncols=500,\n",
    "                                        leave=True)):\n",
    "       try:\n",
    "           # 진행 상황 출력\n",
    "           if i > 0 and i % max(1, total_ts // 20) == 0:\n",
    "               elapsed = time.time() - eval_start_time\n",
    "               items_per_sec = i / elapsed\n",
    "               remaining_items = total_ts - i\n",
    "               est_remaining_sec = remaining_items / items_per_sec\n",
    "               est_remaining_min = est_remaining_sec / 60\n",
    "               print(f\"\\n진행: {i}/{total_ts} ({i/total_ts*100:.1f}%) | \"\n",
    "                     f\"남은 예상 시간: {est_remaining_min:.1f}분\")\n",
    "           \n",
    "           # 모델 평가 실행\n",
    "           result = evaluate_time_series(\n",
    "               ts_id, \n",
    "               domain,\n",
    "               log_transformed_series, \n",
    "               test_size=8,  # 기본 테스트 크기\n",
    "               seasonal_period=4,  # 계절성 주기가 4로 변경됨\n",
    "               optimize_memory=True, \n",
    "               exclude_heavy_models=exclude_heavy_models,\n",
    "               optimal_params=optimal_params,\n",
    "               include_cluster_sarima=include_cluster_sarima\n",
    "           )\n",
    "           \n",
    "           # 메모리 최적화\n",
    "           result = optimize_result_memory(result)\n",
    "           all_results.append(result)\n",
    "           \n",
    "           # 중간 결과 저장\n",
    "           if i+1 == halfway_point:\n",
    "               optimized_results = [optimize_result_memory(r) for r in all_results]\n",
    "               \n",
    "               with open(os.path.join(RESULTS_DIR, 'intermediate_results_50percent.pkl'), 'wb') as f:\n",
    "                   pickle.dump(optimized_results, f)\n",
    "               \n",
    "               elapsed_min = (time.time() - eval_start_time) / 60\n",
    "               print(f\"\\n50% 완료: 현재까지 {elapsed_min:.1f}분 소요\")\n",
    "               \n",
    "               # 가비지 컬렉션\n",
    "               gc.collect()\n",
    "                   \n",
    "       except Exception as e:\n",
    "           print(f\"\\n시계열 {domain}/{ts_id} 처리 중 오류 발생: {e}\")\n",
    "           gc.collect()\n",
    "\n",
    "   # 전체 소요 시간 계산\n",
    "   total_eval_time = time.time() - eval_start_time\n",
    "   print(f\"\\n모든 시계열 평가 완료: 총 {total_eval_time/60:.1f}분 소요\")\n",
    "\n",
    "   # 최종 결과 저장\n",
    "   print(\"모든 시계열 평가 완료. 결과 저장 중...\")\n",
    "   \n",
    "   optimized_results = [optimize_result_memory(r) for r in all_results]\n",
    "   \n",
    "   with open(os.path.join(RESULTS_DIR, 'final_results.pkl'), 'wb') as f:\n",
    "       pickle.dump(optimized_results, f)\n",
    "   \n",
    "   # 결과 요약 및 시각화\n",
    "   summary_df = summarize_model_results(all_results)\n",
    "   summary_df.to_csv(os.path.join(RESULTS_DIR, 'model_summary.csv'), index=False)\n",
    "   \n",
    "   # 도메인별 결과 분석 및 시각화\n",
    "   print(\"\\n결과 시각화 중...\")\n",
    "   visualize_results(all_results, log_transformed_series)\n",
    "   \n",
    "   # 총 소요 시간\n",
    "   total_time = time.time() - start_time\n",
    "   print(f\"\\n총 소요 시간: {total_time:.2f}초 ({total_time/60:.2f}분)\")\n",
    "\n",
    "# 예제 실행\n",
    "if __name__ == \"__main__\":\n",
    "   # 이미 로그 변환된 시계열 데이터가 log_transformed_series 변수에 있다고 가정\n",
    "   # optimal_params는 도메인별 클러스터 파라미터가 포함된 딕셔너리\n",
    "   \n",
    "   main(\n",
    "       log_transformed_series=log_transformed_series,\n",
    "       exclude_heavy_models=False, \n",
    "       include_cluster_sarima=True, \n",
    "       optimal_params=domain_results\n",
    "   )"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
